{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1tOS7oWba4s"
      },
      "source": [
        "# Large language models (LLMs): Part II\n",
        "\n",
        "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
        "\n",
        "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
        "\n",
        "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nU9k28qg_-jo"
      },
      "source": [
        "## Overview\n",
        "1. Training and inference using Hugging Face\n",
        "2. Elements of an LLM\n",
        "3. Attention mechanisms\n",
        "4. Positional encoding\n",
        "5. Output layers\n",
        "6. Training loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbOU5SlN_-jo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
        "os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7YlK2A5_-jo"
      },
      "source": [
        "## LLM training and inference using HuggingFace"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JnO9is8_-jp"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/hf-logo-with-title.png?raw=1\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
        "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
        "Refer to the following links for more information :\n",
        "\n",
        "https://huggingface.co/docs/hub/index\n",
        "\n",
        "https://huggingface.co/docs/transformers/en/index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9GruypV_-jp"
      },
      "source": [
        "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLWQ4WWF_-jp"
      },
      "source": [
        "### Inference\n",
        "\n",
        "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qah38pdP_-jp",
        "outputId": "b12132e0-e9e8-42dd-b073-c0dc174b4009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'My dog really wanted to see me.\"\\n\\nThe father said in a statement that she told him'},\n",
              " {'generated_text': 'My dog really wanted to be back home to feed my little sister, and now I really have no'},\n",
              " {'generated_text': 'My dog really wanted to go to a zoo. But I didn\\'t know where to go.\"\\n'},\n",
              " {'generated_text': 'My dog really wanted to hug you in one place,\" one of the people yelled, and the man'},\n",
              " {'generated_text': 'My dog really wanted to go home, but you would have to go to the hospital to pick her'}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
        "input_text = \"My dog really wanted to\"\n",
        "from transformers import pipeline\n",
        "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
        "generator(input_text, max_length=20, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNollLTz_-jp"
      },
      "source": [
        "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2zj9tfF_-jp"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNm8siMC_-jp"
      },
      "source": [
        "We can also load in our own dataset and train a model with this data as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDFs4bYI_-jp",
        "outputId": "a3adc57c-34e3-490a-dd0a-9fe217a664c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.29.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# pip install accelerate -U\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "tg30TGVM_-jq"
      },
      "outputs": [],
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "rpKONYtS_-jq",
        "outputId": "268afc6e-3fc9-45dc-9661-eeb639d7a02e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-09f0e94acc16>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#The output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# overwrite_output_dir=True, #overwrite the content of the output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \"\"\"\n\u001b[1;32m   1994\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1906\u001b[0m                     \u001b[0;34mf\"Using the `Trainer` with `PyTorch` requires `accelerate>={ACCELERATE_MIN_VERSION}`: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m                     \u001b[0;34m\"Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "train_dataset,test_dataset,data_collator = load_dataset('train_input.txt','test_input.txt', tokenizer)\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./\", #The output directory\n",
        "    # overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 40, # Number of update steps between two evaluations.\n",
        "    save_steps=80, # after # steps model is saved\n",
        "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VL-503t_-jq"
      },
      "source": [
        "## What is going on below the hood?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dSC5zNw_-jq"
      },
      "source": [
        "There are two components that are \"black-boxes\" here:\n",
        "1. The method for tokenization\n",
        "2. The model that generates novel text.\n",
        "\n",
        "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN7r7cxF_-jq"
      },
      "source": [
        "Today we will take a closer look at how the model is designed to deal with language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu9zkZOX_-jr"
      },
      "source": [
        "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4-WJa08_-jr",
        "outputId": "b6e77623-46b1-483e-95c5-982348f72e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-11): 12 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8yBuo91_-jr"
      },
      "source": [
        "## General elements of an LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3q67-4_-jr"
      },
      "source": [
        "GPT-2 is an example of the popular Transformer architecture.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cig2mvfguetQ"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/decoder_only_block.png?raw=1\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
        "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A0DAiBe_-jr"
      },
      "source": [
        "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
        "\n",
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/transformer-decoder-intro.png?raw=1\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
        "Image credit: https://jalammar.github.io/illustrated-gpt2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj9yM0NX_-jr"
      },
      "source": [
        "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers:\n",
        "1. Masked Self-Attention and\n",
        "2. Feed Forward Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-ygfZFi_-js"
      },
      "source": [
        "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhVy_AuS_-js"
      },
      "source": [
        "In this lecture, we will\n",
        "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
        "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
        "* Third, discuss outputting real text/sequences from the models.\n",
        "* Fourth, build a training loop for a mini-LLM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xxem59_e_-js"
      },
      "source": [
        "**Let's set up all the imports we will need**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZa84DWe_-js",
        "outputId": "9bce61b4-c9aa-438b-df41-9ced17a46530"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7bc72868b810>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "## IMPORTS\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowLYFlCrDrr"
      },
      "source": [
        "## Attention mechanisms\n",
        "\n",
        "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
        "\n",
        "`”The animal didn't cross the street because it was too tired”`\n",
        "\n",
        "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
        "\n",
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/viz-bert-voc-verbs.png?raw=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
        "\n",
        "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT05vFUB_-js"
      },
      "source": [
        "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
        "\n",
        "For example, when we read the sentence:\n",
        "`”The animal didn't cross the street because it was too tired”`\n",
        "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
        "\n",
        "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
        "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
        "\n",
        "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0Rs0Pgz_-jt"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/transformer_self-attention_visualization.png?raw=1\" alt=\"Drawing\" style=\"width: 300px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGbAi0cJ7x3a"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXuxylHr_-jt"
      },
      "source": [
        "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
        "1. Query: the word representation we score other words against using the other word's keys\n",
        "2. Key: labels for the words in a sequence that we match against the query\n",
        "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value.\n",
        "\n",
        "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cISf0Eq9_-jt"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/self-attention-example-folders-3.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "Image credit: https://jalammar.github.io/illustrated-gpt2/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcV-jnJc_-jt"
      },
      "source": [
        "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VTNuIH5C_-jt"
      },
      "outputs": [],
      "source": [
        "C = 32 # channels\n",
        "head_size = 16\n",
        "\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzf9VE_AqWeR"
      },
      "source": [
        "The algorithm for self-attention is as follows:\n",
        "\n",
        "1. Generate query, key and value vectors for each word\n",
        "2. Calculate a score for each word in the input sentence against each other.\n",
        "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
        "4. Multiply each value vector by the softmax score.\n",
        "5. Sum up the weighted value vectors to produce the output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGJ8oNpg_-ju"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/self-attention-output.png?raw=1\" alt=\"Drawing\" style=\"width: 450px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOwm-NkXA8U3"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTOFT0ne_-jz"
      },
      "source": [
        "Let's see how attention is performed in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LK0j0o9L_-jz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "B,T,C = 4,8,32 # batch, time, channels\n",
        "x = torch.randn(B,T,C)\n",
        "\n",
        "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
        "\n",
        "head_size = 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "query = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)\n",
        "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
        "q = query(x) # (B, T, 16)\n",
        "v = value(x)\n",
        "\n",
        "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
        "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
        "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
        "\n",
        "out = wei @ v # aggregate the attention scores and value vector.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5J97AFH_-jz",
        "outputId": "059684b6-30f9-413f-9170-e7758426d038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
            "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
            "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
            "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
            "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
            "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
            "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
            "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
            "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
            "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
            "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
            "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
            "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
            "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
            "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
            "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(out[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lwyFlxKW6oA"
      },
      "source": [
        "### Multi-head attention\n",
        "\n",
        "In practice, multiple attention heads are used which\n",
        "1. Expands the model’s ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
        "2. Have multiple “representation subspaces”. Have multiple sets of Query/Key/Value weight matrices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WttbrvAF_-j0"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/transformer_multi-headed_self-attention-recap.png?raw=1\" alt=\"Drawing\" style=\"width: 700px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oHsezdVBIaf"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syu-xXyG_-j0"
      },
      "source": [
        "### Let's see attention mechanisms in action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBrNz0bL_-j0"
      },
      "source": [
        "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2a4xs1f_-j0",
        "outputId": "05d9c401-9d5a-45ff-f171-ab294661d18e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/157.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m153.6/157.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.38.2)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bertviz) (4.66.2)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Downloading boto3-1.34.81-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from bertviz) (2023.12.25)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bertviz) (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0->bertviz) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.0->bertviz) (0.4.2)\n",
            "Collecting botocore<1.35.0,>=1.34.81 (from boto3->bertviz)\n",
            "  Downloading botocore-1.34.81-py3-none-any.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->bertviz)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->bertviz)\n",
            "  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bertviz) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.81->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.81->boto3->bertviz) (1.16.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, bertviz\n",
            "Successfully installed bertviz-1.4.0 boto3-1.34.81 botocore-1.34.81 jmespath-1.0.1 s3transfer-0.10.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bertviz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNEgokGS_-j1"
      },
      "source": [
        "Let's load in the model, GPT2 and look at the attention mechanisms.\n",
        "\n",
        "**Hint... click on the different blocks in the visualization to see the attention**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "VNQjACSD_-j1",
        "outputId": "f1a71fb9-4c19-4e1c-8c36-df5cf000e30b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "      \n",
              "        <div id=\"bertviz-af834f93a11e44c19c8fb48c463825ac\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
              "            <span style=\"user-select:none\">\n",
              "                \n",
              "            </span>\n",
              "            <div id='vis'></div>\n",
              "        </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "/**\n",
              " * @fileoverview Transformer Visualization D3 javascript code.\n",
              " *\n",
              " * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n",
              " *\n",
              " * Change log:\n",
              " *\n",
              " * 02/01/19  Jesse Vig   Initial implementation\n",
              " * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n",
              " * 01/19/21  Jesse Vig   Support light/dark modes\n",
              " * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n",
              " * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n",
              " * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n",
              " **/\n",
              "\n",
              "require.config({\n",
              "  paths: {\n",
              "      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n",
              "    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n",
              "  }\n",
              "});\n",
              "\n",
              "requirejs(['jquery', 'd3'], function($, d3) {\n",
              "\n",
              "        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466980218887329, 0.11987308412790298, 0.1334288865327835, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792069256305695, 0.21213732659816742, 0.06143900007009506, 0.0, 0.0], [0.657085657119751, 0.08996297419071198, 0.1275128275156021, 0.08361561596393585, 0.04182284325361252, 0.0], [0.272887259721756, 0.11203360557556152, 0.16639851033687592, 0.08467116951942444, 0.16952727735042572, 0.19448219239711761]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616553947329521, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.002467755926772952, 0.008448011241853237, 0.9890841841697693, 0.0, 0.0, 0.0], [0.00012328448065090925, 0.0018733128672465682, 0.013126945123076439, 0.9848763942718506, 0.0, 0.0], [0.0010669530602172017, 0.0011366248363628983, 0.0030349865555763245, 0.00157350511290133, 0.9931879043579102, 0.0], [0.00019792001694440842, 0.0010528122074902058, 0.0015437351539731026, 0.0009642756194807589, 3.492440009722486e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4757843017578125, 0.5242156982421875, 0.0, 0.0, 0.0, 0.0], [0.5906046032905579, 0.2486610859632492, 0.1607343554496765, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457568526268005, 0.11392833292484283, 0.0, 0.0], [0.4509407877922058, 0.16486789286136627, 0.17318037152290344, 0.11748013645410538, 0.0935308039188385, 0.0], [0.42572465538978577, 0.17328648269176483, 0.15651948750019073, 0.07022645324468613, 0.0808701142668724, 0.09337276965379715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133622527122498, 0.38663774728775024, 0.0, 0.0, 0.0, 0.0], [0.06098503991961479, 0.03253461420536041, 0.9064803123474121, 0.0, 0.0, 0.0], [0.0067170835100114346, 0.0004012887948192656, 0.7572956085205078, 0.2355860024690628, 0.0, 0.0], [0.03722767531871796, 0.002948855748400092, 0.10081084072589874, 0.04142269492149353, 0.8175899982452393, 0.0], [0.04989771544933319, 0.00030758281354792416, 0.0024198247119784355, 0.0034334948286414146, 0.0006823905860073864, 0.9432590007781982]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.05104443058371544, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.13952411711215973, 0.17833493649959564, 0.0, 0.0, 0.0], [0.20366327464580536, 0.056414876133203506, 0.06399297714233398, 0.6759288907051086, 0.0, 0.0], [0.34195470809936523, 0.067254438996315, 0.0792618840932846, 0.17836201190948486, 0.3331669569015503, 0.0], [0.09464021027088165, 0.007428212556988001, 0.006983972620218992, 0.007184368558228016, 0.018724262714385986, 0.8650389313697815]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834612369537354, 0.6616538763046265, 0.0, 0.0, 0.0, 0.0], [0.07855986058712006, 0.006165443453937769, 0.9152746796607971, 0.0, 0.0, 0.0], [0.016775960102677345, 0.00040376983815804124, 0.0033404543064534664, 0.9794798493385315, 0.0, 0.0], [0.02760043926537037, 0.0004441527707967907, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248193517327309, 3.70155721611809e-05, 0.00016064071678556502, 2.7341899112798274e-05, 1.0187313819187693e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9825032949447632, 0.01749667525291443, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467936769127846, 0.05790088325738907, 0.0, 0.0, 0.0], [0.6849910020828247, 0.12280681729316711, 0.04972028359770775, 0.14248184859752655, 0.0, 0.0], [0.6015853881835938, 0.09881892055273056, 0.07070116698741913, 0.1665254533290863, 0.062369052320718765, 0.0], [0.32325053215026855, 0.12567415833473206, 0.04432179033756256, 0.07076980173587799, 0.06606654077768326, 0.3699170649051666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191646575927734, 0.08083534240722656, 0.0, 0.0, 0.0, 0.0], [0.4598640501499176, 0.39703115820884705, 0.14310480654239655, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181734442710876, 0.3816152513027191, 0.09618015587329865, 0.0, 0.0], [0.18963924050331116, 0.13763725757598877, 0.20173496007919312, 0.2363216131925583, 0.2346668690443039, 0.0], [0.15410453081130981, 0.09489504247903824, 0.11902561038732529, 0.1027795746922493, 0.4317219853401184, 0.09747327864170074]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595212936401367, 0.5519201755523682, 0.20212772488594055, 0.0, 0.0, 0.0], [0.27213579416275024, 0.40738630294799805, 0.251862108707428, 0.06861570477485657, 0.0, 0.0], [0.1024254709482193, 0.16683608293533325, 0.5248051881790161, 0.05445462465286255, 0.15147872269153595, 0.0], [0.2502949833869934, 0.22198131680488586, 0.1889997124671936, 0.10677109658718109, 0.1303267925977707, 0.10162606090307236]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.300949364900589, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.294864296913147, 0.1943414956331253, 0.0, 0.0, 0.0], [0.46047067642211914, 0.28051918745040894, 0.19174796342849731, 0.06726215779781342, 0.0, 0.0], [0.3764842748641968, 0.21120664477348328, 0.20214536786079407, 0.10207021236419678, 0.10809348523616791, 0.0], [0.30138450860977173, 0.20456179976463318, 0.1825033277273178, 0.11019382625818253, 0.16291265189647675, 0.03844384104013443]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.713158369064331, 0.28684163093566895, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063293397426605, 0.41348710656166077, 0.0, 0.0, 0.0], [0.26554614305496216, 0.16985861957073212, 0.3358593285083771, 0.22873590886592865, 0.0, 0.0], [0.31385400891304016, 0.1831670105457306, 0.14928355813026428, 0.05377669632434845, 0.2999187409877777, 0.0], [0.20466554164886475, 0.18731112778186798, 0.15959149599075317, 0.06381770968437195, 0.03642303869128227, 0.3481910526752472]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242318153381, 0.34137576818466187, 0.0, 0.0, 0.0, 0.0], [0.5917777419090271, 0.3160034716129303, 0.09221877157688141, 0.0, 0.0, 0.0], [0.5477151870727539, 0.23586955666542053, 0.06145601347088814, 0.15495926141738892, 0.0, 0.0], [0.4587061107158661, 0.22439998388290405, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743728160858154, 0.19600822031497955, 0.06805708259344101, 0.0892510712146759, 0.11618075519800186, 0.20306557416915894]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448390550911427, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906113028526306, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053596496582, 0.04127567261457443, 0.5496612191200256, 0.029057808220386505, 0.0, 0.0], [0.21445205807685852, 0.050887417048215866, 0.43174412846565247, 0.25869303941726685, 0.04422337934374809, 0.0], [0.11175268143415451, 0.01759307272732258, 0.027507441118359566, 0.04086774215102196, 0.7754669785499573, 0.02681216411292553]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140323519706726, 0.0, 0.0, 0.0, 0.0], [0.6077285408973694, 0.31214284896850586, 0.08012856543064117, 0.0, 0.0, 0.0], [0.49429091811180115, 0.2850370407104492, 0.11849313229322433, 0.1021789088845253, 0.0, 0.0], [0.41838788986206055, 0.2311791181564331, 0.08340615779161453, 0.11365945637226105, 0.1533673107624054, 0.0], [0.4221586287021637, 0.1291714906692505, 0.08740919828414917, 0.10163754224777222, 0.21230259537696838, 0.04732052609324455]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237492620945, 0.0, 0.0, 0.0, 0.0], [0.7749121189117432, 0.0651036873459816, 0.15998415648937225, 0.0, 0.0, 0.0], [0.6484923958778381, 0.07483129948377609, 0.14751604199409485, 0.12916021049022675, 0.0, 0.0], [0.5224636793136597, 0.06921812891960144, 0.13823404908180237, 0.11106594651937485, 0.15901818871498108, 0.0], [0.39645177125930786, 0.07325821369886398, 0.1293814778327942, 0.10642431676387787, 0.14864003658294678, 0.14584419131278992]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740942120552063, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259309053421, 0.22387315332889557, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964668989181519, 0.1549196094274521, 0.1711207777261734, 0.0, 0.0], [0.5039963126182556, 0.11401881277561188, 0.11974020302295685, 0.12552586197853088, 0.13671880960464478, 0.0], [0.5061841607093811, 0.08567394316196442, 0.0890301838517189, 0.09759820997714996, 0.1027572825551033, 0.11875618249177933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257424235343933, 0.07932537794113159, 0.0949321910738945, 0.0, 0.0, 0.0], [0.7306379675865173, 0.08571833372116089, 0.08043932169675827, 0.1032044067978859, 0.0, 0.0], [0.6383240818977356, 0.07886383682489395, 0.07815023511648178, 0.08758097141981125, 0.117080919444561, 0.0], [0.5552157163619995, 0.07409115880727768, 0.06834889203310013, 0.07778602838516235, 0.09999320656061172, 0.12456496059894562]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210855960845947, 0.0, 0.0, 0.0, 0.0], [0.6423036456108093, 0.16629023849964142, 0.19140605628490448, 0.0, 0.0, 0.0], [0.5530978441238403, 0.10609277337789536, 0.07821263372898102, 0.2625967860221863, 0.0, 0.0], [0.4012168049812317, 0.1222359910607338, 0.19347327947616577, 0.14164631068706512, 0.14142754673957825, 0.0], [0.40212583541870117, 0.1845075935125351, 0.07516805827617645, 0.058490391820669174, 0.14446339011192322, 0.13524475693702698]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844046026468277, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.062332455068826675, 0.05468333512544632, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617087453603745, 0.07321774214506149, 0.030065858736634254, 0.0, 0.0], [0.6819811463356018, 0.04990815743803978, 0.08296556025743484, 0.08369529247283936, 0.10144980996847153, 0.0], [0.4056687355041504, 0.07337656617164612, 0.08601398020982742, 0.06170930340886116, 0.13226443529129028, 0.24096696078777313]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670192003250122, 0.03298087790608406, 0.0, 0.0, 0.0, 0.0], [0.8449065089225769, 0.08514498919248581, 0.06994851678609848, 0.0, 0.0, 0.0], [0.7123571038246155, 0.07896049320697784, 0.055410757660865784, 0.1532716304063797, 0.0, 0.0], [0.640261173248291, 0.0739755630493164, 0.044393062591552734, 0.14322136342525482, 0.09814884513616562, 0.0], [0.5073902606964111, 0.07523062080144882, 0.07754648476839066, 0.11362482607364655, 0.13947948813438416, 0.08672824501991272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487567901611328, 0.15124322474002838, 0.0, 0.0, 0.0, 0.0], [0.8415648341178894, 0.1210724338889122, 0.03736277297139168, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348951607942581, 0.061799556016922, 0.07415911555290222, 0.0, 0.0], [0.6614715456962585, 0.10242648422718048, 0.052934277802705765, 0.0752972960472107, 0.10787033289670944, 0.0], [0.6014202237129211, 0.11340402066707611, 0.05631927400827408, 0.07096727937459946, 0.10906262695789337, 0.04882659390568733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545159429311752, 0.0, 0.0, 0.0, 0.0], [0.8874567747116089, 0.05474221706390381, 0.057801052927970886, 0.0, 0.0, 0.0], [0.8281887769699097, 0.06895007193088531, 0.05903473123908043, 0.04382641240954399, 0.0, 0.0], [0.6429893970489502, 0.06747540831565857, 0.11629702895879745, 0.05417948588728905, 0.11905863881111145, 0.0], [0.7367823123931885, 0.056119006127119064, 0.06857286393642426, 0.034219563007354736, 0.07875377684831619, 0.025552386417984962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913392090704292, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981202797964215, 0.5288337469100952, 0.4703681766986847, 0.0, 0.0, 0.0], [0.0007648473256267607, 0.3451983630657196, 0.3085266649723053, 0.3455101251602173, 0.0, 0.0], [0.0010283150477334857, 0.24135911464691162, 0.23320142924785614, 0.2555714249610901, 0.26883965730667114, 0.0], [0.0009746808791533113, 0.17789694666862488, 0.1674315482378006, 0.18587610125541687, 0.18734434247016907, 0.2804763615131378]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8244927525520325, 0.17550718784332275, 0.0, 0.0, 0.0, 0.0], [0.12386851012706757, 0.044499825686216354, 0.8316316604614258, 0.0, 0.0, 0.0], [0.07924355566501617, 0.012965913861989975, 0.0015277150087058544, 0.9062628149986267, 0.0, 0.0], [0.08806417882442474, 0.02134108357131481, 0.0028886189684271812, 0.002845388138666749, 0.8848607540130615, 0.0], [0.09983226656913757, 0.03363394737243652, 0.005499998107552528, 0.00243305298499763, 0.0015082467580214143, 0.8570924997329712]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529155015945435, 0.08733480423688889, 0.15974965691566467, 0.0, 0.0, 0.0], [0.42022842168807983, 0.09195113927125931, 0.23549841344356537, 0.25232207775115967, 0.0, 0.0], [0.3084895610809326, 0.05908143147826195, 0.3839128613471985, 0.15659146010875702, 0.09192463010549545, 0.0], [0.447904109954834, 0.04329312965273857, 0.07969177514314651, 0.1108192726969719, 0.2212459146976471, 0.09704578667879105]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904017508029938, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084477081894875, 0.004147926811128855, 0.0, 0.0, 0.0], [0.9082902073860168, 0.03320597484707832, 0.009421153925359249, 0.04908263683319092, 0.0, 0.0], [0.8949136137962341, 0.055445361882448196, 0.005577605217695236, 0.03150679171085358, 0.012556544505059719, 0.0], [0.8497737050056458, 0.028890114277601242, 0.0036648025270551443, 0.03751996532082558, 0.038428016006946564, 0.041723549365997314]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474484534934163, 0.0, 0.0, 0.0, 0.0], [0.4894773066043854, 0.48122045397758484, 0.02930225059390068, 0.0, 0.0, 0.0], [0.11772146075963974, 0.13121247291564941, 0.67023104429245, 0.08083496242761612, 0.0, 0.0], [0.13043726980686188, 0.0406869612634182, 0.2652043104171753, 0.41143471002578735, 0.15223680436611176, 0.0], [0.12661851942539215, 0.03275134041905403, 0.03567883372306824, 0.06039177253842354, 0.6021823287010193, 0.14237718284130096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482314586639404, 0.0, 0.0, 0.0, 0.0], [0.7948848009109497, 0.12061930447816849, 0.0844959020614624, 0.0, 0.0, 0.0], [0.5612354874610901, 0.15743164718151093, 0.2033972144126892, 0.07793562114238739, 0.0, 0.0], [0.4258382320404053, 0.10742025077342987, 0.15123654901981354, 0.08754990994930267, 0.22795499861240387, 0.0], [0.24752630293369293, 0.024188317358493805, 0.030395260080695152, 0.08586960285902023, 0.5714336633682251, 0.04058684781193733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223198845982552, 0.0, 0.0, 0.0, 0.0], [0.7572691440582275, 0.22317387163639069, 0.0195570457726717, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107607126235962, 0.17621813714504242, 0.0685177892446518, 0.0, 0.0], [0.17095306515693665, 0.08229431509971619, 0.5760217905044556, 0.11097602546215057, 0.0597548633813858, 0.0], [0.2487107813358307, 0.08880821615457535, 0.08980182558298111, 0.09729332476854324, 0.4413091838359833, 0.03407657518982887]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.84221351146698, 0.1577865481376648, 0.0, 0.0, 0.0, 0.0], [0.46841251850128174, 0.4610540270805359, 0.07053346186876297, 0.0, 0.0, 0.0], [0.25881412625312805, 0.46358928084373474, 0.18503478169441223, 0.09256181120872498, 0.0, 0.0], [0.18399572372436523, 0.29154250025749207, 0.17031069099903107, 0.2717295289039612, 0.08242153376340866, 0.0], [0.16469858586788177, 0.24727003276348114, 0.08770552277565002, 0.2257496416568756, 0.1774536818265915, 0.09712250530719757]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005395531654358, 0.0, 0.0, 0.0, 0.0], [0.9068723320960999, 0.044065166264772415, 0.049062490463256836, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348340421915054, 0.040419381111860275, 0.046010058373212814, 0.0, 0.0], [0.7855251431465149, 0.041242457926273346, 0.08369290828704834, 0.04887617751955986, 0.04066329449415207, 0.0], [0.7856318354606628, 0.0501464419066906, 0.04751264303922653, 0.027365924790501595, 0.0561474971473217, 0.03319565951824188]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041034579277039, 0.09589655697345734, 0.0, 0.0, 0.0, 0.0], [0.5862311720848083, 0.07199837267398834, 0.3417704999446869, 0.0, 0.0, 0.0], [0.38789618015289307, 0.046608004719018936, 0.20278996229171753, 0.36270585656166077, 0.0, 0.0], [0.2665242850780487, 0.02453301101922989, 0.12211935967206955, 0.20041202008724213, 0.3864113688468933, 0.0], [0.2335740178823471, 0.020537324249744415, 0.09610337764024734, 0.13062253594398499, 0.2299049347639084, 0.28925779461860657]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.03600878641009331, 0.0, 0.0, 0.0, 0.0], [0.7075549960136414, 0.25427794456481934, 0.03816710785031319, 0.0, 0.0, 0.0], [0.25665247440338135, 0.2058933526277542, 0.016656633466482162, 0.520797610282898, 0.0, 0.0], [0.10379401594400406, 0.04639105498790741, 0.00869862549006939, 0.7866847515106201, 0.05443162843585014, 0.0], [0.22143346071243286, 0.033797502517700195, 0.029023950919508934, 0.541292130947113, 0.15286119282245636, 0.0215916745364666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829640552401543, 0.0, 0.0, 0.0, 0.0], [0.7913153767585754, 0.12309644371271133, 0.08558813482522964, 0.0, 0.0, 0.0], [0.2954603135585785, 0.15808317065238953, 0.4217239022254944, 0.12473267316818237, 0.0, 0.0], [0.23441052436828613, 0.09886535257101059, 0.33160147070884705, 0.19713923335075378, 0.13798339664936066, 0.0], [0.19728368520736694, 0.05741846561431885, 0.06909020990133286, 0.1646982580423355, 0.2797277271747589, 0.2317817062139511]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.06408718228340149, 0.0, 0.0, 0.0, 0.0], [0.7888625860214233, 0.0867348238825798, 0.12440251559019089, 0.0, 0.0, 0.0], [0.6535119414329529, 0.07573550939559937, 0.09732570499181747, 0.17342683672904968, 0.0, 0.0], [0.5222766995429993, 0.05827884376049042, 0.09920478612184525, 0.1702084094285965, 0.15003129839897156, 0.0], [0.4108838438987732, 0.047306086868047714, 0.07265683263540268, 0.10560749471187592, 0.10550011694431305, 0.25804561376571655]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683831930160522, 0.031616728752851486, 0.0, 0.0, 0.0, 0.0], [0.896539568901062, 0.03887060284614563, 0.06458979845046997, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213466331362724, 0.051967162638902664, 0.08940286934375763, 0.0, 0.0], [0.7718175053596497, 0.030402861535549164, 0.04582742601633072, 0.07118464261293411, 0.08076757192611694, 0.0], [0.7292331457138062, 0.021699873730540276, 0.033074744045734406, 0.04720093309879303, 0.06474556028842926, 0.10404572635889053]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432821474969387, 0.0, 0.0, 0.0, 0.0], [0.9552940726280212, 0.008025333285331726, 0.03668065741658211, 0.0, 0.0, 0.0], [0.9254711270332336, 0.00275557953864336, 0.002062988467514515, 0.06971034407615662, 0.0, 0.0], [0.8660575151443481, 0.003888372564688325, 0.0006785987643525004, 0.0006981458282098174, 0.12867732346057892, 0.0], [0.8455936908721924, 0.0037804015446454287, 0.0002534226223360747, 6.0270347603363916e-05, 0.00011820702638942748, 0.150193989276886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455701828003, 0.07375437766313553, 0.0, 0.0, 0.0, 0.0], [0.7717147469520569, 0.1624203771352768, 0.06586486846208572, 0.0, 0.0, 0.0], [0.8167640566825867, 0.07807155698537827, 0.06324019283056259, 0.04192415252327919, 0.0, 0.0], [0.6867176294326782, 0.07755190879106522, 0.1005692109465599, 0.05955103039741516, 0.07561030983924866, 0.0], [0.6421176791191101, 0.11014875024557114, 0.07688140124082565, 0.05403309315443039, 0.1033359244465828, 0.013483130373060703]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395952820777893, 0.06040477007627487, 0.0, 0.0, 0.0, 0.0], [0.2300449162721634, 0.6617392301559448, 0.10821589082479477, 0.0, 0.0, 0.0], [0.26702260971069336, 0.3607953190803528, 0.3249623775482178, 0.04721971973776817, 0.0, 0.0], [0.5952032804489136, 0.12269210070371628, 0.06302005052566528, 0.08916770666837692, 0.12991684675216675, 0.0], [0.1028466448187828, 0.029380010440945625, 0.01373895350843668, 0.04586036503314972, 0.7698498964309692, 0.03832418471574783]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040982723236084, 0.0959017425775528, 0.0, 0.0, 0.0, 0.0], [0.357235312461853, 0.6274638175964355, 0.015300935134291649, 0.0, 0.0, 0.0], [0.5918000936508179, 0.27640387415885925, 0.1047603040933609, 0.027035744860768318, 0.0, 0.0], [0.7254436612129211, 0.04983079805970192, 0.01498265191912651, 0.17781229317188263, 0.03193056955933571, 0.0], [0.7612767219543457, 0.06158901005983353, 0.005942164920270443, 0.01642669551074505, 0.12677954137325287, 0.02798592671751976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816435545682907, 0.018942005932331085, 0.0, 0.0, 0.0], [0.9671075940132141, 0.008509604260325432, 0.00856224074959755, 0.015820497646927834, 0.0, 0.0], [0.9340998530387878, 0.011952383443713188, 0.020180154591798782, 0.026750771328806877, 0.007016891613602638, 0.0], [0.9587240219116211, 0.0046570925042033195, 0.003326763864606619, 0.006545269396156073, 0.010182411409914494, 0.016564475372433662]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.02300085686147213, 0.0, 0.0, 0.0, 0.0], [0.791760265827179, 0.1753326654434204, 0.032907143235206604, 0.0, 0.0, 0.0], [0.7949190735816956, 0.10531850159168243, 0.04021850973367691, 0.05954388156533241, 0.0, 0.0], [0.7097727060317993, 0.10552525520324707, 0.06597540527582169, 0.05765572935342789, 0.06107088923454285, 0.0], [0.7506603598594666, 0.026514418423175812, 0.02157600037753582, 0.034296635538339615, 0.08494450896978378, 0.08200804889202118]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.01624833419919014, 0.0, 0.0, 0.0, 0.0], [0.5615487694740295, 0.08956838399171829, 0.3488827645778656, 0.0, 0.0, 0.0], [0.3292914927005768, 0.024114832282066345, 0.5428048968315125, 0.10378878563642502, 0.0, 0.0], [0.34330493211746216, 0.013086404651403427, 0.5121950507164001, 0.11146263778209686, 0.01995093934237957, 0.0], [0.4792822599411011, 0.017333481460809708, 0.11805278062820435, 0.06130271032452583, 0.20071901381015778, 0.12330969423055649]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115317836403847, 0.0, 0.0, 0.0, 0.0], [0.5282679200172424, 0.3292284309864044, 0.14250363409519196, 0.0, 0.0, 0.0], [0.48788732290267944, 0.233686164021492, 0.17577986419200897, 0.10264668613672256, 0.0, 0.0], [0.31444936990737915, 0.18065084517002106, 0.16871292889118195, 0.09506543725728989, 0.24112139642238617, 0.0], [0.5168782472610474, 0.03589695692062378, 0.026187807321548462, 0.040397077798843384, 0.18791691958904266, 0.19272294640541077]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750306367874146, 0.12496936321258545, 0.0, 0.0, 0.0, 0.0], [0.4550616145133972, 0.4900423586368561, 0.05489595979452133, 0.0, 0.0, 0.0], [0.29337263107299805, 0.5449898838996887, 0.09444298595190048, 0.06719449907541275, 0.0, 0.0], [0.4897097647190094, 0.2720980942249298, 0.06861936300992966, 0.14694873988628387, 0.02262401394546032, 0.0], [0.4729084074497223, 0.08103056997060776, 0.01605204865336418, 0.3067218065261841, 0.10120705515146255, 0.022080253809690475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697795420885086, 0.0, 0.0, 0.0, 0.0], [0.7557179927825928, 0.1643647700548172, 0.07991719990968704, 0.0, 0.0, 0.0], [0.6947709918022156, 0.08409848809242249, 0.06382585316896439, 0.15730471909046173, 0.0, 0.0], [0.5821163654327393, 0.03297785297036171, 0.07936536520719528, 0.1944136917591095, 0.11112680286169052, 0.0], [0.5974539518356323, 0.04261082038283348, 0.06919696182012558, 0.14563480019569397, 0.12481768429279327, 0.02028587833046913]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217814654111862, 0.0, 0.0, 0.0, 0.0], [0.9312829971313477, 0.010560262948274612, 0.058156777173280716, 0.0, 0.0, 0.0], [0.8435326218605042, 0.015694990754127502, 0.045751187950372696, 0.09502114355564117, 0.0, 0.0], [0.7724104523658752, 0.011981194838881493, 0.035046011209487915, 0.038767579942941666, 0.14179480075836182, 0.0], [0.7642906904220581, 0.00986877828836441, 0.008122753351926804, 0.013314371928572655, 0.04824399948120117, 0.15615928173065186]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701175093650818, 0.029882490634918213, 0.0, 0.0, 0.0, 0.0], [0.6563995480537415, 0.22506217658519745, 0.11853817850351334, 0.0, 0.0, 0.0], [0.6958061456680298, 0.1470184177160263, 0.07145984470844269, 0.08571554720401764, 0.0, 0.0], [0.6353272795677185, 0.13460662961006165, 0.030994117259979248, 0.05691640451550484, 0.1421555131673813, 0.0], [0.6779407262802124, 0.05365397781133652, 0.018006201833486557, 0.06284506618976593, 0.11038198322057724, 0.07717210799455643]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822332859039307, 0.01776670478284359, 0.0, 0.0, 0.0, 0.0], [0.9037660956382751, 0.06541543453931808, 0.030818426981568336, 0.0, 0.0, 0.0], [0.8119187355041504, 0.036790236830711365, 0.06056087091565132, 0.09073004871606827, 0.0, 0.0], [0.40546342730522156, 0.10383892804384232, 0.10211260616779327, 0.3543427288532257, 0.03424236178398132, 0.0], [0.22824503481388092, 0.017278604209423065, 0.05055435746908188, 0.6015732288360596, 0.09411737322807312, 0.008231470361351967]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685154564678669, 0.0, 0.0, 0.0, 0.0], [0.354457825422287, 0.531760036945343, 0.11378218978643417, 0.0, 0.0, 0.0], [0.07823401689529419, 0.7221351265907288, 0.10936620831489563, 0.09026475995779037, 0.0, 0.0], [0.21968045830726624, 0.40484222769737244, 0.1235806941986084, 0.2001885175704956, 0.051708124577999115, 0.0], [0.36089763045310974, 0.1045902818441391, 0.06983798742294312, 0.29764822125434875, 0.13869896531105042, 0.028326835483312607]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732161164283752, 0.026783881708979607, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.06145283579826355, 0.02179183065891266, 0.0, 0.0, 0.0], [0.8543079495429993, 0.08049621433019638, 0.03033490665256977, 0.03486097976565361, 0.0, 0.0], [0.8919220566749573, 0.04280766472220421, 0.022044911980628967, 0.023470569401979446, 0.01975482702255249, 0.0], [0.8116769194602966, 0.03413527458906174, 0.03567648306488991, 0.04748578742146492, 0.025397121906280518, 0.045628443360328674]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761363983154, 0.04972386732697487, 0.0, 0.0, 0.0, 0.0], [0.7637453675270081, 0.20073619484901428, 0.03551839664578438, 0.0, 0.0, 0.0], [0.6279090046882629, 0.037681419402360916, 0.19945412874221802, 0.13495545089244843, 0.0, 0.0], [0.6397066712379456, 0.027007192373275757, 0.09081999957561493, 0.20653821527957916, 0.03592786192893982, 0.0], [0.45594266057014465, 0.02164124697446823, 0.12939591705799103, 0.21800900995731354, 0.10379799455404282, 0.07121305912733078]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498405456542969, 0.05015944689512253, 0.0, 0.0, 0.0, 0.0], [0.868872344493866, 0.08722198009490967, 0.04390567168593407, 0.0, 0.0, 0.0], [0.6937950849533081, 0.06359203159809113, 0.09179060161113739, 0.1508222371339798, 0.0, 0.0], [0.7266592383384705, 0.04389891028404236, 0.046839818358421326, 0.09851827472448349, 0.08408384770154953, 0.0], [0.7848992943763733, 0.037147846072912216, 0.012907843105494976, 0.010539384558796883, 0.12079204618930817, 0.03371358662843704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089461799710989, 0.0, 0.0, 0.0, 0.0], [0.8929510116577148, 0.08700131624937057, 0.020047729834914207, 0.0, 0.0, 0.0], [0.7891115546226501, 0.09797312319278717, 0.0863322764635086, 0.026583032682538033, 0.0, 0.0], [0.8850637674331665, 0.0364501029253006, 0.053954314440488815, 0.012377242557704449, 0.01215458381921053, 0.0], [0.6861329078674316, 0.057203810662031174, 0.0116362813860178, 0.02166050672531128, 0.17488020658493042, 0.048486314713954926]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396193027496338, 0.06038068234920502, 0.0, 0.0, 0.0, 0.0], [0.7851802110671997, 0.19751375913619995, 0.01730601117014885, 0.0, 0.0, 0.0], [0.7660512328147888, 0.15444660186767578, 0.0318828783929348, 0.04761931300163269, 0.0, 0.0], [0.7035237550735474, 0.05171409994363785, 0.0776095986366272, 0.15339010953903198, 0.013762442395091057, 0.0], [0.7121893763542175, 0.04994220659136772, 0.03772540017962456, 0.08649095147848129, 0.06541402637958527, 0.04823804274201393]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927739217877388, 0.0, 0.0, 0.0, 0.0], [0.7925394773483276, 0.011715609580278397, 0.19574493169784546, 0.0, 0.0, 0.0], [0.5106772184371948, 0.007296781521290541, 0.03962003067135811, 0.44240593910217285, 0.0, 0.0], [0.5862484574317932, 0.01209966279566288, 0.024585144594311714, 0.06737807393074036, 0.30968865752220154, 0.0], [0.3019636273384094, 0.007724008988589048, 0.011518117040395737, 0.04694722592830658, 0.2214670479297638, 0.41037997603416443]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554461918771267, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.00803192425519228, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.02595478855073452, 0.04210774973034859, 0.0, 0.0], [0.9400084614753723, 0.00555663276463747, 0.005828281864523888, 0.031757764518260956, 0.016849050298333168, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646713569760323, 0.013360859826207161, 0.03543969988822937, 0.030003685504198074]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.02083336003124714, 0.0, 0.0, 0.0, 0.0], [0.8444863557815552, 0.13507835566997528, 0.020435357466340065, 0.0, 0.0, 0.0], [0.7903085947036743, 0.14559166133403778, 0.037530042231082916, 0.026569712907075882, 0.0, 0.0], [0.7298934459686279, 0.05649632588028908, 0.03273547440767288, 0.10400423407554626, 0.07687054574489594, 0.0], [0.5684199929237366, 0.04388810321688652, 0.026293331757187843, 0.08117101341485977, 0.2431478202342987, 0.037079744040966034]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.050013184547424316, 0.0, 0.0, 0.0, 0.0], [0.9336171746253967, 0.05848868191242218, 0.007894255220890045, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071813106536865, 0.05360180512070656, 0.045896656811237335, 0.0, 0.0], [0.8859304785728455, 0.05752970278263092, 0.013743232935667038, 0.0033877352252602577, 0.03940894827246666, 0.0], [0.9337607622146606, 0.026470666751265526, 0.004523405339568853, 0.0061904969625175, 0.01413296815007925, 0.014921738766133785]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521648659231005e-09, 0.0, 0.0, 0.0, 0.0], [6.6758143475453835e-06, 0.9999804496765137, 1.284119480260415e-05, 0.0, 0.0, 0.0], [2.219406880499264e-08, 2.668508969350114e-09, 0.9999971389770508, 2.813725814121426e-06, 0.0, 0.0], [1.0145217856916133e-06, 4.4640319885047575e-08, 0.0003535518771968782, 0.9993677735328674, 0.00027762516401708126, 0.0], [9.436730286083161e-10, 1.3820468207359493e-11, 5.017710691390675e-10, 2.9652009736480522e-09, 0.9999971389770508, 2.864445150407846e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.00513678602874279, 0.0, 0.0, 0.0, 0.0], [0.9274216890335083, 0.018323812633752823, 0.05425459146499634, 0.0, 0.0, 0.0], [0.9678993225097656, 0.0041434201411902905, 0.004314461722970009, 0.023642871528863907, 0.0, 0.0], [0.899907648563385, 0.0014671608805656433, 0.00029133600764907897, 0.002585014561191201, 0.09574881941080093, 0.0], [0.9386116862297058, 0.00022248241293709725, 0.000614665390457958, 0.0015495705883949995, 0.030689310282468796, 0.02831241302192211]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042735781695228e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613615985610522e-06, 0.001720665255561471, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376233727678482e-07, 0.00011847116547869518, 0.0, 0.0], [0.9996154308319092, 3.4731792197817413e-07, 3.892067468314053e-08, 4.468433303372876e-07, 0.00038369561661966145, 0.0], [0.9994840621948242, 1.6550142589721872e-08, 2.871539450666205e-08, 1.0638284493325045e-06, 0.00021266516705509275, 0.0003021192387677729]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586443066596985, 0.0, 0.0, 0.0, 0.0], [0.5749930143356323, 0.39028263092041016, 0.03472428396344185, 0.0, 0.0, 0.0], [0.744231641292572, 0.1752413809299469, 0.07564764469861984, 0.004879307933151722, 0.0, 0.0], [0.5232048034667969, 0.09429354965686798, 0.11381909251213074, 0.199794739484787, 0.06888782978057861, 0.0], [0.4747248888015747, 0.05636602267622948, 0.045303650200366974, 0.06967318058013916, 0.3098025918006897, 0.044129688292741776]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734647631645203, 0.12653520703315735, 0.0, 0.0, 0.0, 0.0], [0.6097909212112427, 0.3541729748249054, 0.03603604808449745, 0.0, 0.0, 0.0], [0.4598419666290283, 0.3869785964488983, 0.09960105270147324, 0.05357832461595535, 0.0, 0.0], [0.5722200274467468, 0.23636257648468018, 0.08344569057226181, 0.06921947747468948, 0.038752224296331406, 0.0], [0.514358401298523, 0.16722990572452545, 0.09019368141889572, 0.0765446200966835, 0.10578057914972305, 0.045892804861068726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771234899759293, 0.0, 0.0, 0.0, 0.0], [0.6142938137054443, 0.35039809346199036, 0.03530815243721008, 0.0, 0.0, 0.0], [0.5770687460899353, 0.32858437299728394, 0.05508258566260338, 0.03926431015133858, 0.0, 0.0], [0.17188090085983276, 0.011042523197829723, 0.05457884445786476, 0.7326592803001404, 0.02983849309384823, 0.0], [0.3783024251461029, 0.017070062458515167, 0.021754097193479538, 0.4409683644771576, 0.06093815341591835, 0.08096696436405182]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709759831428528, 0.033411506563425064, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787286351434886, 0.0006868178606964648, 0.002304842695593834, 0.0, 0.0], [0.9935757517814636, 0.003263507504016161, 0.0009993839776143432, 0.0002793238090816885, 0.001882061013020575, 0.0], [0.9907532930374146, 0.00021344359265640378, 0.0004595248610712588, 0.0007905631209723651, 0.004424731712788343, 0.003358363639563322]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130659103394, 0.1365436464548111, 0.044043250381946564, 0.0, 0.0, 0.0], [0.7584242820739746, 0.006878956686705351, 0.20653414726257324, 0.028162650763988495, 0.0, 0.0], [0.5298121571540833, 0.002678812248632312, 0.07857993245124817, 0.3598378598690033, 0.029091132804751396, 0.0], [0.754442572593689, 0.0003678239299915731, 0.001971345627680421, 0.003240057732909918, 0.19423308968544006, 0.04574507102370262]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749132394790649, 0.025086797773838043, 0.0, 0.0, 0.0, 0.0], [0.9306469559669495, 0.057056792080402374, 0.012296278029680252, 0.0, 0.0, 0.0], [0.9305251836776733, 0.05277099460363388, 0.011119411326944828, 0.005584418307989836, 0.0, 0.0], [0.8863323926925659, 0.012924155220389366, 0.017724651843309402, 0.06150183826684952, 0.021517043933272362, 0.0], [0.7916852831840515, 0.015036062337458134, 0.031747858971357346, 0.033922016620635986, 0.03707969933748245, 0.09052912145853043]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.960849940776825, 0.039150021970272064, 0.0, 0.0, 0.0, 0.0], [0.9121273159980774, 0.022576453164219856, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364106059074402, 0.01558446604758501, 0.024544961750507355, 0.023459969088435173, 0.0, 0.0], [0.9454619288444519, 0.006762297358363867, 0.022026164457201958, 0.009137828834354877, 0.0166118573397398, 0.0], [0.8346167802810669, 0.0018816972151398659, 0.005609032232314348, 0.01887362077832222, 0.1244916245341301, 0.014527121558785439]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.003577286144718528, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453043937683105, 0.004154064226895571, 0.0, 0.0, 0.0], [0.9735792279243469, 0.01900341734290123, 0.0036644143983721733, 0.003752920078113675, 0.0, 0.0], [0.9586310982704163, 0.007116200402379036, 0.009218422695994377, 0.02272571064531803, 0.0023084881249815226, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512503676116467, 0.0036064486484974623, 0.004877470899373293, 0.006167230196297169]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024012047797441483, 0.0, 0.0, 0.0, 0.0], [0.946063756942749, 0.04211379587650299, 0.011822430416941643, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293113946914673, 0.05218193307518959, 0.0602056086063385, 0.0, 0.0], [0.9378372430801392, 0.03354857116937637, 0.008826462551951408, 0.0028792363591492176, 0.016908491030335426, 0.0], [0.8124933838844299, 0.026967575773596764, 0.05999194458127022, 0.03445727750658989, 0.011011868715286255, 0.05507809296250343]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001206755638123, 0.09987929463386536, 0.0, 0.0, 0.0, 0.0], [0.6271925568580627, 0.07988723367452621, 0.2929201126098633, 0.0, 0.0, 0.0], [0.7624078989028931, 0.02734428085386753, 0.03867945075035095, 0.17156831920146942, 0.0, 0.0], [0.7995962500572205, 0.014336277730762959, 0.014375667087733746, 0.025438543409109116, 0.1462532877922058, 0.0], [0.7851975560188293, 0.04204043000936508, 0.025253599509596825, 0.02908393368124962, 0.029306255280971527, 0.08911828696727753]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.004553207661956549, 0.0, 0.0, 0.0, 0.0], [0.9356004595756531, 0.04476727917790413, 0.019632209092378616, 0.0, 0.0, 0.0], [0.5605551600456238, 0.09862001240253448, 0.2998324930667877, 0.04099231958389282, 0.0, 0.0], [0.589370608329773, 0.1100098192691803, 0.08033646643161774, 0.16754046082496643, 0.0527426153421402, 0.0], [0.223059743642807, 0.056807976216077805, 0.05467941239476204, 0.24733929336071014, 0.3111240565776825, 0.10698945075273514]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301448464393616, 0.06985516101121902, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535714447498322, 0.020995058119297028, 0.0, 0.0, 0.0], [0.8404536843299866, 0.10619213432073593, 0.023636789992451668, 0.029717300087213516, 0.0, 0.0], [0.8927381634712219, 0.02478480525314808, 0.008319051936268806, 0.05165467783808708, 0.022503303363919258, 0.0], [0.8646609783172607, 0.009503169916570187, 0.00243298034183681, 0.04796737805008888, 0.042732127010822296, 0.032703299075365067]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037402346730232, 0.0, 0.0, 0.0, 0.0], [0.9702038764953613, 0.01680702343583107, 0.012989096343517303, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064444556832314, 0.013456214219331741, 0.018002301454544067, 0.0, 0.0], [0.9332928657531738, 0.018971974030137062, 0.020146867260336876, 0.017023736611008644, 0.010564574971795082, 0.0], [0.9113593697547913, 0.012528610415756702, 0.022096145898103714, 0.017518552020192146, 0.01851789653301239, 0.01797933503985405]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182312101125717, 0.0, 0.0, 0.0, 0.0], [0.9096419215202332, 0.07916687428951263, 0.011191246099770069, 0.0, 0.0, 0.0], [0.8379933834075928, 0.13078251481056213, 0.012140998616814613, 0.019083019345998764, 0.0, 0.0], [0.9116523265838623, 0.05451972037553787, 0.00949938129633665, 0.007465865928679705, 0.016862763091921806, 0.0], [0.8510287404060364, 0.07338211685419083, 0.008022502064704895, 0.009083151817321777, 0.04261011257767677, 0.015873325988650322]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.02009769156575203, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063263908028603, 0.015062462538480759, 0.0, 0.0, 0.0], [0.7943130731582642, 0.06074107438325882, 0.0690767914056778, 0.0758691281080246, 0.0, 0.0], [0.549432098865509, 0.031547121703624725, 0.054820187389850616, 0.0578807033598423, 0.306319922208786, 0.0], [0.645397961139679, 0.010770927183330059, 0.017528077587485313, 0.02157982438802719, 0.24958311021327972, 0.05514014512300491]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506808519363403, 0.049319129437208176, 0.0, 0.0, 0.0, 0.0], [0.8553208708763123, 0.09256317466497421, 0.05211597681045532, 0.0, 0.0, 0.0], [0.8508525490760803, 0.04734596610069275, 0.04417724534869194, 0.057624202221632004, 0.0, 0.0], [0.7697128653526306, 0.027885887771844864, 0.031017253175377846, 0.06842502951622009, 0.10295900702476501, 0.0], [0.7931906580924988, 0.040521834045648575, 0.029241926968097687, 0.04478121176362038, 0.04894692823290825, 0.04331746697425842]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.022968946024775505, 0.0, 0.0, 0.0, 0.0], [0.9429818391799927, 0.017321474850177765, 0.03969673812389374, 0.0, 0.0, 0.0], [0.9144347906112671, 0.008583571761846542, 0.013035777024924755, 0.06394589692354202, 0.0, 0.0], [0.9222431182861328, 0.003644028678536415, 0.003740261774510145, 0.010410326533019543, 0.05996226519346237, 0.0], [0.9198879599571228, 0.0030822642147541046, 0.0034827410709112883, 0.0042068008333444595, 0.021254301071166992, 0.04808594286441803]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9774582386016846, 0.02254181168973446, 0.0, 0.0, 0.0, 0.0], [0.8929324150085449, 0.07475479692220688, 0.032312821596860886, 0.0, 0.0, 0.0], [0.8423513174057007, 0.05980277061462402, 0.037400756031274796, 0.060445044189691544, 0.0, 0.0], [0.7674633264541626, 0.035363439470529556, 0.04215509817004204, 0.06658629328012466, 0.08843192458152771, 0.0], [0.6182613372802734, 0.016110623255372047, 0.020167628303170204, 0.03868889808654785, 0.2314697951078415, 0.0753016546368599]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514345556497574, 0.0, 0.0, 0.0, 0.0], [0.43639448285102844, 0.5226364731788635, 0.040969014167785645, 0.0, 0.0, 0.0], [0.36086124181747437, 0.35129690170288086, 0.2655107080936432, 0.02233118563890457, 0.0, 0.0], [0.39429229497909546, 0.021704625338315964, 0.07794322818517685, 0.3716890215873718, 0.13437077403068542, 0.0], [0.6310721635818481, 0.016983957961201668, 0.025942014530301094, 0.08615921437740326, 0.21831963956356049, 0.021522965282201767]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826387739740312, 0.005030233412981033, 0.0, 0.0, 0.0], [0.9981209635734558, 2.7051630240748636e-05, 0.00011307397653581575, 0.0017389433924108744, 0.0, 0.0], [0.9982239603996277, 6.836584361735731e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.001545313629321754, 0.0], [0.9982888102531433, 1.0552178082434693e-06, 3.278081203461625e-05, 0.0001303895260207355, 0.0006605856469832361, 0.0008863675757311285]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328933872282505, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561349716037512, 0.025375083088874817, 0.0, 0.0, 0.0], [0.9724301099777222, 0.00195861142128706, 0.011192452162504196, 0.014418844133615494, 0.0, 0.0], [0.9782041311264038, 0.0009589171386323869, 0.001870649284683168, 0.006326562725007534, 0.01263973768800497, 0.0], [0.9592596888542175, 0.002455513458698988, 0.0016124167013913393, 0.005019667558372021, 0.006687135435640812, 0.024965722113847733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709990158677101, 0.0, 0.0, 0.0, 0.0], [0.36802080273628235, 0.6152244210243225, 0.016754813492298126, 0.0, 0.0, 0.0], [0.31735214591026306, 0.6140003800392151, 0.053751468658447266, 0.014896074309945107, 0.0, 0.0], [0.4898741543292999, 0.21071387827396393, 0.04693012312054634, 0.20700415968894958, 0.04547771066427231, 0.0], [0.48774242401123047, 0.1769523322582245, 0.06915220618247986, 0.09849317371845245, 0.12091425806283951, 0.04674568027257919]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.02055807039141655, 0.0, 0.0, 0.0, 0.0], [0.6677890419960022, 0.31032490730285645, 0.021886074915528297, 0.0, 0.0, 0.0], [0.711875855922699, 0.11108537018299103, 0.14187364280223846, 0.03516502305865288, 0.0, 0.0], [0.4501466155052185, 0.04036048427224159, 0.04045815393328667, 0.3885694742202759, 0.0804651752114296, 0.0], [0.49346205592155457, 0.013696958310902119, 0.00812679436057806, 0.13074517250061035, 0.30861401557922363, 0.04535504803061485]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394601970911026, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713806349784136, 0.011612341739237309, 0.0, 0.0, 0.0], [0.9326630234718323, 0.01957845874130726, 0.024103542789816856, 0.02365495264530182, 0.0, 0.0], [0.9422018527984619, 0.0009538960293866694, 0.0010898001492023468, 0.0031933635473251343, 0.05256103351712227, 0.0], [0.9352929592132568, 0.0010279365815222263, 0.004444439895451069, 0.0016371352830901742, 0.010590966790914536, 0.047006525099277496]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216770650818944, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178908171132207, 0.009547143243253231, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218825915828347, 0.0017900299280881882, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.868332441925304e-06, 2.3676169803366065e-05, 0.0012337109073996544, 0.0], [0.9971562623977661, 1.8522179743740708e-05, 1.8826593759513344e-06, 2.7900150598725304e-05, 0.0006533485138788819, 0.002141993958503008]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176709190011024, 0.0, 0.0, 0.0, 0.0], [0.919467568397522, 0.050882015377283096, 0.029650306329131126, 0.0, 0.0, 0.0], [0.8474555015563965, 0.06100171059370041, 0.04372366517782211, 0.047819141298532486, 0.0, 0.0], [0.8011622428894043, 0.041867081075906754, 0.04375801607966423, 0.041894808411598206, 0.07131782919168472, 0.0], [0.8031870126724243, 0.024504918605089188, 0.01732351817190647, 0.0474439337849617, 0.06109936535358429, 0.04644131660461426]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736391067505, 0.09492656588554382, 0.018699748441576958, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696347773075104, 0.03219832852482796, 0.007729670964181423, 0.0, 0.0], [0.9068530201911926, 0.01604657620191574, 0.014310453087091446, 0.04543779417872429, 0.01735224947333336, 0.0], [0.6555968523025513, 0.05091030150651932, 0.028384873643517494, 0.125655397772789, 0.1054687574505806, 0.03398393467068672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.04976809769868851, 0.0, 0.0, 0.0, 0.0], [0.8829867243766785, 0.1000962033867836, 0.01691715233027935, 0.0, 0.0, 0.0], [0.8057456016540527, 0.14463560283184052, 0.03018922172486782, 0.01942945271730423, 0.0, 0.0], [0.8706232905387878, 0.03244058042764664, 0.02695159800350666, 0.04410297051072121, 0.025881517678499222, 0.0], [0.6883644461631775, 0.00968148186802864, 0.016449354588985443, 0.09871124476194382, 0.08971203118562698, 0.09708139300346375]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.020731747150421143, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933869183063507, 0.02173773944377899, 0.0, 0.0, 0.0], [0.9144353866577148, 0.017671285197138786, 0.02235853485763073, 0.045534808188676834, 0.0, 0.0], [0.9448293447494507, 0.006467591971158981, 0.006386054679751396, 0.03263082355260849, 0.009686139412224293, 0.0], [0.9347907304763794, 0.007862498052418232, 0.007788168732076883, 0.02143275924026966, 0.008491129614412785, 0.0196347888559103]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9833701848983765, 0.01662975549697876, 0.0, 0.0, 0.0, 0.0], [0.9631112813949585, 0.009229970164597034, 0.02765871398150921, 0.0, 0.0, 0.0], [0.9706628322601318, 0.004149409011006355, 0.006813114508986473, 0.01837460696697235, 0.0, 0.0], [0.987951934337616, 0.0021658889017999172, 0.0003490102826617658, 0.001583811710588634, 0.007949435152113438, 0.0], [0.945794939994812, 0.014583585783839226, 0.00036529666977003217, 0.0009569558897055686, 0.01362166740000248, 0.024677546694874763]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.012194057926535606, 0.0, 0.0, 0.0, 0.0], [0.8710366487503052, 0.0944816991686821, 0.03448163717985153, 0.0, 0.0, 0.0], [0.6309780478477478, 0.11090393364429474, 0.1923023909330368, 0.06581564992666245, 0.0, 0.0], [0.5360495448112488, 0.04618944227695465, 0.13605298101902008, 0.2645546793937683, 0.01715332642197609, 0.0], [0.8287513852119446, 0.02373281493782997, 0.02008042484521866, 0.07245299965143204, 0.0304313562810421, 0.02455105073750019]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043143481016159, 0.0, 0.0, 0.0, 0.0], [0.270342618227005, 0.6504339575767517, 0.07922345399856567, 0.0, 0.0, 0.0], [0.20541740953922272, 0.5892512798309326, 0.180857852101326, 0.02447350136935711, 0.0, 0.0], [0.5573872327804565, 0.17741312086582184, 0.0880676656961441, 0.09881818294525146, 0.07831382751464844, 0.0], [0.5922901034355164, 0.08700644969940186, 0.056432779878377914, 0.05685899406671524, 0.1218155100941658, 0.08559606969356537]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316376447677612, 0.068362295627594, 0.0, 0.0, 0.0, 0.0], [0.9572947025299072, 0.02624349854886532, 0.016461782157421112, 0.0, 0.0, 0.0], [0.9880544543266296, 0.004273331258445978, 0.0029545812867581844, 0.004717642907053232, 0.0, 0.0], [0.99403977394104, 0.0009413447696715593, 0.00047398178139701486, 0.00011646964412648231, 0.004428428132086992, 0.0], [0.9806035161018372, 2.5468958483543247e-05, 0.00016239396063610911, 0.0001476412871852517, 0.001344241201877594, 0.017716852948069572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821870803833008, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.013184132054448128, 0.011163455434143543, 0.0, 0.0, 0.0], [0.9418967962265015, 0.004721763078123331, 0.0023818148765712976, 0.0509997121989727, 0.0, 0.0], [0.9905040860176086, 0.0022848148364573717, 6.19848578935489e-05, 0.0005984479794278741, 0.006550685502588749, 0.0], [0.9697661399841309, 0.0008878838270902634, 0.0002346673863939941, 0.0017040770035237074, 0.004128350410610437, 0.02327890321612358]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716230630874634, 0.0283768679946661, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907284140586853, 0.048730771988630295, 0.0, 0.0, 0.0], [0.8426315784454346, 0.02387218549847603, 0.04748142883181572, 0.0860147550702095, 0.0, 0.0], [0.8521116375923157, 0.020744290202856064, 0.044946324080228806, 0.05765015631914139, 0.024547478184103966, 0.0], [0.8800724744796753, 0.02244853600859642, 0.01823573186993599, 0.01925482228398323, 0.015854286029934883, 0.04413414001464844]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412722587585449, 0.05872778967022896, 0.0, 0.0, 0.0, 0.0], [0.9163140654563904, 0.05759185180068016, 0.026094017550349236, 0.0, 0.0, 0.0], [0.8392423987388611, 0.05769050121307373, 0.013829062692821026, 0.08923796564340591, 0.0, 0.0], [0.8987160921096802, 0.013477860949933529, 0.0003456451231613755, 0.0032987555023282766, 0.08416163921356201, 0.0], [0.8701690435409546, 0.0027008659671992064, 0.0014349978882819414, 0.0056661684066057205, 0.08874314278364182, 0.031285740435123444]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432748094201088, 0.0, 0.0, 0.0, 0.0], [0.9178615212440491, 0.062257926911115646, 0.019880497828125954, 0.0, 0.0, 0.0], [0.8233146667480469, 0.06282396614551544, 0.03670436143875122, 0.07715708762407303, 0.0, 0.0], [0.8501746654510498, 0.03816923871636391, 0.031964968889951706, 0.05160145089030266, 0.028089623898267746, 0.0], [0.6572403907775879, 0.0587739571928978, 0.04336011782288551, 0.09013210982084274, 0.08146586269140244, 0.06902758777141571]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162064790725708, 0.083793506026268, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.040992818772792816, 0.013829846866428852, 0.0, 0.0, 0.0], [0.8928354978561401, 0.05368676036596298, 0.01759696751832962, 0.035880785435438156, 0.0, 0.0], [0.8337051868438721, 0.04799617826938629, 0.033513251692056656, 0.0468086414039135, 0.03797678276896477, 0.0], [0.8167194724082947, 0.06337127834558487, 0.013286269269883633, 0.020469754934310913, 0.025292271748185158, 0.06086096167564392]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748661443591118, 0.0, 0.0, 0.0, 0.0], [0.30198633670806885, 0.6520944833755493, 0.045919183641672134, 0.0, 0.0, 0.0], [0.2855835556983948, 0.5569521188735962, 0.14447391033172607, 0.012990497052669525, 0.0, 0.0], [0.8438040018081665, 0.03225131705403328, 0.03954288363456726, 0.06848171353340149, 0.01592012494802475, 0.0], [0.6664936542510986, 0.06095915287733078, 0.04064338654279709, 0.06804481148719788, 0.09186346083879471, 0.07199545204639435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682656526565552, 0.031734418123960495, 0.0, 0.0, 0.0, 0.0], [0.7385215759277344, 0.22856871783733368, 0.03290969505906105, 0.0, 0.0, 0.0], [0.5946669578552246, 0.23033174872398376, 0.1486765593290329, 0.02632465586066246, 0.0, 0.0], [0.6339261531829834, 0.058130085468292236, 0.09654293209314346, 0.14291933178901672, 0.06848142296075821, 0.0], [0.40375757217407227, 0.08945360779762268, 0.07635073363780975, 0.255870521068573, 0.14330360293388367, 0.031263869255781174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020600192248821, 0.0, 0.0, 0.0, 0.0], [0.863138735294342, 0.11056642234325409, 0.026294825598597527, 0.0, 0.0, 0.0], [0.9488077759742737, 0.02861507050693035, 0.006535581778734922, 0.016041584312915802, 0.0, 0.0], [0.9672170877456665, 0.006604989990592003, 0.0004517161869443953, 0.004844421520829201, 0.020881719887256622, 0.0], [0.9354623556137085, 0.0204780176281929, 0.001170022296719253, 0.007056924514472485, 0.016318105161190033, 0.01951460912823677]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.01533269602805376, 0.0, 0.0, 0.0, 0.0], [0.9052745699882507, 0.08373622596263885, 0.010989241302013397, 0.0, 0.0, 0.0], [0.814594030380249, 0.042837489396333694, 0.10568274557590485, 0.0368858203291893, 0.0, 0.0], [0.23519699275493622, 0.012018428184092045, 0.05280094966292381, 0.6516199111938477, 0.048363760113716125, 0.0], [0.31818681955337524, 0.01863236539065838, 0.03948163613677025, 0.3755547106266022, 0.20787166059017181, 0.040272727608680725]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826739862561226, 0.0, 0.0, 0.0, 0.0], [0.8618937730789185, 0.0647917315363884, 0.07331447303295135, 0.0, 0.0, 0.0], [0.7664536833763123, 0.07330439984798431, 0.10353528708219528, 0.05670657008886337, 0.0, 0.0], [0.8128500580787659, 0.03215484321117401, 0.05900546908378601, 0.05416510999202728, 0.04182443022727966, 0.0], [0.8687862157821655, 0.02698776312172413, 0.02046988718211651, 0.01629730872809887, 0.032183703035116196, 0.035275109112262726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264581799507141, 0.07354183495044708, 0.0, 0.0, 0.0, 0.0], [0.8403534293174744, 0.06373776495456696, 0.0959087386727333, 0.0, 0.0, 0.0], [0.7330995202064514, 0.06451123207807541, 0.10380081832408905, 0.09858846664428711, 0.0, 0.0], [0.9143611788749695, 0.008257807232439518, 0.007320408709347248, 0.01796630211174488, 0.05209442973136902, 0.0], [0.8971914052963257, 0.008555497974157333, 0.007019439246505499, 0.014860527589917183, 0.03399759903550148, 0.03837534412741661]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180346727371216, 0.08196533471345901, 0.0, 0.0, 0.0, 0.0], [0.8328660726547241, 0.12199065834283829, 0.045143257826566696, 0.0, 0.0, 0.0], [0.7994153499603271, 0.08744156360626221, 0.03605782240629196, 0.07708528637886047, 0.0, 0.0], [0.8809850215911865, 0.02074967324733734, 0.020554570481181145, 0.01712082512676716, 0.060589876025915146, 0.0], [0.7453039288520813, 0.04433402791619301, 0.022549191489815712, 0.033152736723423004, 0.03357040509581566, 0.12108971923589706]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293899595737457, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414142489433289, 0.0054081035777926445, 0.0, 0.0, 0.0], [0.96304851770401, 0.015290786512196064, 0.010345697402954102, 0.011314956471323967, 0.0, 0.0], [0.9213568568229675, 0.014132496900856495, 0.017639189958572388, 0.016567690297961235, 0.030303703621029854, 0.0], [0.9373330473899841, 0.009064311161637306, 0.007548339664936066, 0.006576436571776867, 0.011827593669295311, 0.027650361880660057]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407953947782516, 0.010991264134645462, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523805662989616, 0.03914501518011093, 0.02311362884938717, 0.0, 0.0], [0.9534734487533569, 0.008932976052165031, 0.015272831544280052, 0.007908296771347523, 0.01441233605146408, 0.0], [0.9427104592323303, 0.008233043365180492, 0.0046509732492268085, 0.004178094677627087, 0.0054635051637887955, 0.03476400673389435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543375372886658, 0.04566241055727005, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.019547609612345695, 0.010848305188119411, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425409629940987, 0.008068887516856194, 0.008460711687803268, 0.0, 0.0], [0.9726192951202393, 0.002697661053389311, 0.0004483141237869859, 0.0013814771082252264, 0.022853175178170204, 0.0], [0.9675466418266296, 0.009613418020308018, 0.0032030276488512754, 0.004248825367540121, 0.0074422359466552734, 0.007945875637233257]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299148201942444, 0.0, 0.0, 0.0, 0.0], [0.9382631182670593, 0.04204246401786804, 0.019694389775395393, 0.0, 0.0, 0.0], [0.8351995944976807, 0.034878626465797424, 0.051344748586416245, 0.07857709378004074, 0.0, 0.0], [0.9042678475379944, 0.010541587136685848, 0.016426727175712585, 0.02592189982533455, 0.04284190386533737, 0.0], [0.8913140296936035, 0.008912663906812668, 0.005010687280446291, 0.00817559752613306, 0.013514691032469273, 0.07307220995426178]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693915009498596, 0.13060854375362396, 0.0, 0.0, 0.0, 0.0], [0.3507999777793884, 0.6063508987426758, 0.0428491048514843, 0.0, 0.0, 0.0], [0.35475727915763855, 0.3502015769481659, 0.24722374975681305, 0.04781733825802803, 0.0, 0.0], [0.35370829701423645, 0.03527732938528061, 0.09567102789878845, 0.4497946500778198, 0.06554868817329407, 0.0], [0.41325902938842773, 0.09055528044700623, 0.05286572128534317, 0.17467984557151794, 0.17384859919548035, 0.0947914645075798]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.03702434524893761, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.019658586010336876, 0.00469872634857893, 0.0, 0.0, 0.0], [0.9775736331939697, 0.013286303728818893, 0.002559040440246463, 0.006581075489521027, 0.0, 0.0], [0.9870141744613647, 0.007388271391391754, 0.000957920856308192, 0.001831832341849804, 0.0028077582828700542, 0.0], [0.9409245848655701, 0.016633689403533936, 0.0022979099303483963, 0.005890651606023312, 0.005512924864888191, 0.02874019183218479]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9628270864486694, 0.03717285394668579, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641864001750946, 0.017134418711066246, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331589616835117, 0.014810995198786259, 0.03472748026251793, 0.0, 0.0], [0.9225173592567444, 0.010528748854994774, 0.011010152287781239, 0.019440028816461563, 0.03650377318263054, 0.0], [0.8420167565345764, 0.04357195645570755, 0.007488266099244356, 0.01496153511106968, 0.023852793499827385, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.007361333351582289, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.003346970770508051, 0.00091368897119537, 0.0, 0.0, 0.0], [0.9869900345802307, 0.0019747859332710505, 0.0015245546819642186, 0.009510686621069908, 0.0, 0.0], [0.9933527708053589, 0.001020328258164227, 0.00034337403485551476, 0.001029114704579115, 0.004254393745213747, 0.0], [0.9749016761779785, 0.0004348019137978554, 0.000430655520176515, 0.0012364384019747376, 0.001534773618914187, 0.021461637690663338]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252486914396286, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.016509056091308594, 0.00442709494382143, 0.0, 0.0, 0.0], [0.9521436095237732, 0.02943236567080021, 0.008943174965679646, 0.009480932727456093, 0.0, 0.0], [0.9395942091941833, 0.021510910242795944, 0.010278534144163132, 0.004555221181362867, 0.024061065167188644, 0.0], [0.9205074310302734, 0.01615365780889988, 0.010818609036505222, 0.01664443127810955, 0.014566411264240742, 0.02130948379635811]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898502826690674, 0.01014977227896452, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.0069075338542461395, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.0089876102283597, 0.015342569909989834, 0.007170100696384907, 0.0, 0.0], [0.9274120330810547, 0.009485269896686077, 0.02206611819565296, 0.03222890570759773, 0.008807665668427944, 0.0], [0.9006660580635071, 0.02162371575832367, 0.013808215968310833, 0.009843839332461357, 0.008521351031959057, 0.04553685709834099]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555594641715288, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460234332829714, 0.0022854835260659456, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.0040722922421991825, 0.008166342042386532, 0.0, 0.0], [0.9889963865280151, 0.0012260458897799253, 0.0007996382773853838, 0.0006774249486625195, 0.008300590328872204, 0.0], [0.9865202903747559, 0.0003942706680390984, 0.0009571767877787352, 0.0004954360192641616, 0.0009604952065274119, 0.010672261007130146]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870519310235977, 0.0, 0.0, 0.0, 0.0], [0.7489445805549622, 0.22002629935741425, 0.03102915547788143, 0.0, 0.0, 0.0], [0.2854783236980438, 0.21125619113445282, 0.47871607542037964, 0.024549338966608047, 0.0, 0.0], [0.8056642413139343, 0.02697453647851944, 0.04302811250090599, 0.06993735581636429, 0.05439591035246849, 0.0], [0.330721914768219, 0.022326510399580002, 0.016627032309770584, 0.080194391310215, 0.41574740409851074, 0.13438260555267334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225370079278946, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.01501889992505312, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764732390642166, 0.006302398629486561, 0.017146700993180275, 0.0, 0.0], [0.9451842904090881, 0.03618054464459419, 0.001989212818443775, 0.0039587244391441345, 0.01268730964511633, 0.0], [0.9633325934410095, 0.018663031980395317, 0.0030418476089835167, 0.007070912979543209, 0.0050094276666641235, 0.0028820668812841177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.987324595451355, 0.012675448320806026, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.005541946738958359, 0.004001116845756769, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.00372527539730072, 0.010124039836227894, 0.0, 0.0], [0.9744364619255066, 0.004632262047380209, 0.002379997167736292, 0.006518092937767506, 0.012033062055706978, 0.0], [0.9624499678611755, 0.0033743453677743673, 0.0013198527740314603, 0.0017274925485253334, 0.002944671083241701, 0.028183719143271446]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807673692703247, 0.019232625141739845, 0.0, 0.0, 0.0, 0.0], [0.9664247035980225, 0.0154139194637537, 0.01816137507557869, 0.0, 0.0, 0.0], [0.9632683396339417, 0.004538131412118673, 0.0029253889806568623, 0.029268164187669754, 0.0, 0.0], [0.9562349915504456, 0.0012223643716424704, 0.0005304075893945992, 0.008671474643051624, 0.033340781927108765, 0.0], [0.9657101035118103, 0.0009808274917304516, 0.0016686212038621306, 0.0026348272804170847, 0.005866338964551687, 0.02313929796218872]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639714956283569, 0.036028504371643066, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.033733122050762177, 0.009986838325858116, 0.0, 0.0, 0.0], [0.853999674320221, 0.08073031902313232, 0.03334450349211693, 0.031925544142723083, 0.0, 0.0], [0.9547489881515503, 0.0096050426363945, 0.00414617033675313, 0.002013325458392501, 0.02948645129799843, 0.0], [0.933113694190979, 0.028699707239866257, 0.005477478262037039, 0.006368071772158146, 0.012613070197403431, 0.013728084973990917]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.060700662434101105, 0.0, 0.0, 0.0, 0.0], [0.9298389554023743, 0.061895497143268585, 0.008265494368970394, 0.0, 0.0, 0.0], [0.8471820950508118, 0.09035064280033112, 0.017636114731431007, 0.04483110085129738, 0.0, 0.0], [0.8857702016830444, 0.03918180242180824, 0.007867713458836079, 0.022765880450606346, 0.0444144681096077, 0.0], [0.8563281893730164, 0.10088981688022614, 0.00653143459931016, 0.008485895581543446, 0.0073684388771653175, 0.020396238192915916]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353262543678284, 0.16467373073101044, 0.0, 0.0, 0.0, 0.0], [0.6160860061645508, 0.3137648403644562, 0.07014918327331543, 0.0, 0.0, 0.0], [0.34316354990005493, 0.27584975957870483, 0.11966027319431305, 0.261326402425766, 0.0, 0.0], [0.5908167958259583, 0.05029088631272316, 0.04166605323553085, 0.2199493646621704, 0.09727690368890762, 0.0], [0.8481416702270508, 0.0631808340549469, 0.014733636751770973, 0.05526723712682724, 0.009014973416924477, 0.009661651216447353]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627320766448975, 0.03726791962981224, 0.0, 0.0, 0.0, 0.0], [0.7757521867752075, 0.17996282875537872, 0.044284969568252563, 0.0, 0.0, 0.0], [0.6317057609558105, 0.24380743503570557, 0.10925643891096115, 0.015230290591716766, 0.0, 0.0], [0.9539909958839417, 0.01818232797086239, 0.011601817794144154, 0.01229910645633936, 0.003925777971744537, 0.0], [0.40357086062431335, 0.14237552881240845, 0.056611865758895874, 0.19757317006587982, 0.09299169480800629, 0.10687682777643204]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.01973811723291874, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808676429092884, 0.0, 0.0, 0.0], [0.9283919334411621, 0.00830123946070671, 0.01330562774091959, 0.05000118911266327, 0.0, 0.0], [0.8981053829193115, 0.015591327100992203, 0.01017757598310709, 0.03998705744743347, 0.03613865002989769, 0.0], [0.975350022315979, 0.0003543295315466821, 0.0005866009742021561, 0.0011877480428665876, 0.0010750859510153532, 0.021446382626891136]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.0704670250415802, 0.0, 0.0, 0.0, 0.0], [0.9361505508422852, 0.04116692394018173, 0.022682547569274902, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802806839346886, 0.024856165051460266, 0.0684337243437767, 0.0, 0.0], [0.8661178946495056, 0.02232472598552704, 0.010369138792157173, 0.026001976802945137, 0.07518625259399414, 0.0], [0.8074422478675842, 0.04438253492116928, 0.01849709264934063, 0.03357789292931557, 0.0185612291097641, 0.07753899693489075]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680536389350891, 0.031946372240781784, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.025684954598546028, 0.004946068394929171, 0.0, 0.0, 0.0], [0.9620568156242371, 0.02255246415734291, 0.005471329670399427, 0.00991946179419756, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.0007573263137601316, 0.0028828911017626524, 0.013469814322888851, 0.0], [0.9624637365341187, 0.00311090424656868, 0.00100075569935143, 0.0019475899171084166, 0.008266208693385124, 0.023210842162370682]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542505502700806, 0.14574943482875824, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116342179477215, 0.013286862522363663, 0.0, 0.0, 0.0], [0.9257622957229614, 0.03257261589169502, 0.014612065628170967, 0.02705308608710766, 0.0, 0.0], [0.7923429012298584, 0.027305010706186295, 0.01880667358636856, 0.1385413110256195, 0.02300402708351612, 0.0], [0.6152051091194153, 0.026655299589037895, 0.029352962970733643, 0.0559089221060276, 0.11611286550760269, 0.15676498413085938]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534558057785034, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.0075094737112522125, 0.004245333839207888, 0.0, 0.0, 0.0], [0.9584206342697144, 0.010963579639792442, 0.010456085205078125, 0.020159730687737465, 0.0, 0.0], [0.9604810476303101, 0.007182636763900518, 0.003072344930842519, 0.0068989223800599575, 0.022365106269717216, 0.0], [0.966888964176178, 0.0032812876161187887, 0.005500528495758772, 0.004234079271554947, 0.005038034170866013, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498193860054016, 0.050180625170469284, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.005433559417724609, 0.0, 0.0, 0.0], [0.8618695139884949, 0.03609364852309227, 0.07555560022592545, 0.026481211185455322, 0.0, 0.0], [0.5449836850166321, 0.015411168336868286, 0.02351653389632702, 0.25743618607521057, 0.1586524099111557, 0.0], [0.9571872353553772, 0.0030803889967501163, 0.001444686553440988, 0.006861576810479164, 0.014818795025348663, 0.01660728268325329]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156561374664307, 0.3843438923358917, 0.0, 0.0, 0.0, 0.0], [0.36760637164115906, 0.4281637370586395, 0.20422989130020142, 0.0, 0.0, 0.0], [0.16471558809280396, 0.4136791527271271, 0.25092360377311707, 0.1706816852092743, 0.0, 0.0], [0.4184460937976837, 0.15247608721256256, 0.10305383056402206, 0.11071506887674332, 0.21530893445014954, 0.0], [0.19686944782733917, 0.2014620304107666, 0.12827250361442566, 0.0920325294137001, 0.09167566150426865, 0.28968778252601624]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027365446090698, 0.09726346284151077, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004308730363846, 0.012332303449511528, 0.0, 0.0, 0.0], [0.8504457473754883, 0.05690574273467064, 0.03206087276339531, 0.06058763712644577, 0.0, 0.0], [0.766120970249176, 0.035303935408592224, 0.03433044254779816, 0.09675208479166031, 0.06749249249696732, 0.0], [0.8650376796722412, 0.020085245370864868, 0.0114980423822999, 0.018558325245976448, 0.018430287018418312, 0.06639042496681213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469175100326538, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176092110574245, 0.004191520158201456, 0.0, 0.0, 0.0], [0.9275255799293518, 0.0473722405731678, 0.011528268456459045, 0.013573979958891869, 0.0, 0.0], [0.9293115139007568, 0.025833338499069214, 0.007227125111967325, 0.01430062297731638, 0.023327331990003586, 0.0], [0.8895061612129211, 0.046896226704120636, 0.004717112518846989, 0.006286595948040485, 0.006090151146054268, 0.046503737568855286]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619737207889557, 0.0, 0.0, 0.0, 0.0], [0.8221706748008728, 0.063044972717762, 0.11478440463542938, 0.0, 0.0, 0.0], [0.5047378540039062, 0.15375757217407227, 0.22770363092422485, 0.11380091309547424, 0.0, 0.0], [0.40820738673210144, 0.09066358208656311, 0.11696857213973999, 0.24553203582763672, 0.13862840831279755, 0.0], [0.7291041016578674, 0.06638885289430618, 0.023112762719392776, 0.03110307641327381, 0.05714317411184311, 0.09314802289009094]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247532486915588, 0.07524676620960236, 0.0, 0.0, 0.0, 0.0], [0.8957375288009644, 0.06989562511444092, 0.03436676785349846, 0.0, 0.0, 0.0], [0.7924938201904297, 0.09601156413555145, 0.055091120302677155, 0.056403499096632004, 0.0, 0.0], [0.7891507148742676, 0.07880303263664246, 0.03840154409408569, 0.05396977812051773, 0.039674971252679825, 0.0], [0.780785858631134, 0.07993540912866592, 0.04253171756863594, 0.03234210982918739, 0.017816951498389244, 0.04658801481127739]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191135033965111, 0.0, 0.0, 0.0, 0.0], [0.8636949062347412, 0.047562092542648315, 0.08874304592609406, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224130108952522, 0.022624509409070015, 0.021014362573623657, 0.0, 0.0], [0.9588144421577454, 0.008020910434424877, 0.004490078892558813, 0.00586229981854558, 0.022812405601143837, 0.0], [0.938591718673706, 0.02122773416340351, 0.0048724752850830555, 0.010940182954072952, 0.009524590335786343, 0.01484343409538269]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626603186130524, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189403425902128, 0.006330370437353849, 0.0, 0.0, 0.0], [0.9477092027664185, 0.017985165119171143, 0.0101566007360816, 0.024149015545845032, 0.0, 0.0], [0.967192530632019, 0.006552820093929768, 0.003322787582874298, 0.005563332699239254, 0.017368430271744728, 0.0], [0.9584562182426453, 0.007502953987568617, 0.0051363264210522175, 0.008071641437709332, 0.005997130647301674, 0.014835829846560955]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.993125319480896, 0.0050708153285086155, 0.0018038052367046475, 0.0, 0.0, 0.0], [0.9534158110618591, 0.023829087615013123, 0.007748983334749937, 0.015006095170974731, 0.0, 0.0], [0.9151288270950317, 0.010873124934732914, 0.013190999627113342, 0.011050461791455746, 0.049756716936826706, 0.0], [0.8769674301147461, 0.03385210409760475, 0.008486478589475155, 0.009969156235456467, 0.03468579426407814, 0.036039117723703384]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.52503949822858e-05, 0.37378302216529846, 0.6261518001556396, 0.0, 0.0, 0.0], [4.606039874488488e-05, 0.21050886809825897, 0.411596417427063, 0.377848744392395, 0.0, 0.0], [4.7531026211800054e-05, 0.11616962403059006, 0.23264268040657043, 0.3985332250595093, 0.2526068687438965, 0.0], [1.2476449455789407e-06, 0.1481970250606537, 0.15813151001930237, 0.30074411630630493, 0.11939028650522232, 0.273535817861557]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.02844420075416565, 0.0, 0.0, 0.0, 0.0], [0.9529063701629639, 0.03233078494668007, 0.014762787148356438, 0.0, 0.0, 0.0], [0.9343128204345703, 0.023512953892350197, 0.020498033612966537, 0.021676233038306236, 0.0, 0.0], [0.9529678225517273, 0.00855142343789339, 0.004359327722340822, 0.008064564317464828, 0.026056958362460136, 0.0], [0.9653593897819519, 0.008487634360790253, 0.003499275306239724, 0.002721574855968356, 0.0032828773837536573, 0.016649343073368073]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692186772823334, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.08513346314430237, 0.14525090157985687, 0.0, 0.0, 0.0], [0.7133336067199707, 0.1017090305685997, 0.11931272596120834, 0.06564465165138245, 0.0, 0.0], [0.7186216711997986, 0.05444302782416344, 0.013868178240954876, 0.0780804380774498, 0.13498668372631073, 0.0], [0.7990152835845947, 0.058055855333805084, 0.009447006508708, 0.017770448699593544, 0.021138517186045647, 0.09457287937402725]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.04810114949941635, 0.0, 0.0, 0.0, 0.0], [0.8580654263496399, 0.029445774853229523, 0.11248882114887238, 0.0, 0.0, 0.0], [0.6577739119529724, 0.08513441681861877, 0.12613077461719513, 0.1309608817100525, 0.0, 0.0], [0.8087368607521057, 0.03230159357190132, 0.018418151885271072, 0.06856140494346619, 0.07198190689086914, 0.0], [0.668330192565918, 0.13281351327896118, 0.021880602464079857, 0.02787742204964161, 0.049234092235565186, 0.09986425936222076]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-af834f93a11e44c19c8fb48c463825ac\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780149072408676, 0.0, 0.0, 0.0, 0.0], [0.7466980218887329, 0.11987308412790298, 0.1334288865327835, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792069256305695, 0.21213732659816742, 0.06143900007009506, 0.0, 0.0], [0.657085657119751, 0.08996297419071198, 0.1275128275156021, 0.08361561596393585, 0.04182284325361252, 0.0], [0.272887259721756, 0.11203360557556152, 0.16639851033687592, 0.08467116951942444, 0.16952727735042572, 0.19448219239711761]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616553947329521, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.002467755926772952, 0.008448011241853237, 0.9890841841697693, 0.0, 0.0, 0.0], [0.00012328448065090925, 0.0018733128672465682, 0.013126945123076439, 0.9848763942718506, 0.0, 0.0], [0.0010669530602172017, 0.0011366248363628983, 0.0030349865555763245, 0.00157350511290133, 0.9931879043579102, 0.0], [0.00019792001694440842, 0.0010528122074902058, 0.0015437351539731026, 0.0009642756194807589, 3.492440009722486e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4757843017578125, 0.5242156982421875, 0.0, 0.0, 0.0, 0.0], [0.5906046032905579, 0.2486610859632492, 0.1607343554496765, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457568526268005, 0.11392833292484283, 0.0, 0.0], [0.4509407877922058, 0.16486789286136627, 0.17318037152290344, 0.11748013645410538, 0.0935308039188385, 0.0], [0.42572465538978577, 0.17328648269176483, 0.15651948750019073, 0.07022645324468613, 0.0808701142668724, 0.09337276965379715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133622527122498, 0.38663774728775024, 0.0, 0.0, 0.0, 0.0], [0.06098503991961479, 0.03253461420536041, 0.9064803123474121, 0.0, 0.0, 0.0], [0.0067170835100114346, 0.0004012887948192656, 0.7572956085205078, 0.2355860024690628, 0.0, 0.0], [0.03722767531871796, 0.002948855748400092, 0.10081084072589874, 0.04142269492149353, 0.8175899982452393, 0.0], [0.04989771544933319, 0.00030758281354792416, 0.0024198247119784355, 0.0034334948286414146, 0.0006823905860073864, 0.9432590007781982]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.05104443058371544, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.13952411711215973, 0.17833493649959564, 0.0, 0.0, 0.0], [0.20366327464580536, 0.056414876133203506, 0.06399297714233398, 0.6759288907051086, 0.0, 0.0], [0.34195470809936523, 0.067254438996315, 0.0792618840932846, 0.17836201190948486, 0.3331669569015503, 0.0], [0.09464021027088165, 0.007428212556988001, 0.006983972620218992, 0.007184368558228016, 0.018724262714385986, 0.8650389313697815]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834612369537354, 0.6616538763046265, 0.0, 0.0, 0.0, 0.0], [0.07855986058712006, 0.006165443453937769, 0.9152746796607971, 0.0, 0.0, 0.0], [0.016775960102677345, 0.00040376983815804124, 0.0033404543064534664, 0.9794798493385315, 0.0, 0.0], [0.02760043926537037, 0.0004441527707967907, 0.0006541680195368826, 0.0002266185765620321, 0.971074640750885, 0.0], [0.010248193517327309, 3.70155721611809e-05, 0.00016064071678556502, 2.7341899112798274e-05, 1.0187313819187693e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9825032949447632, 0.01749667525291443, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467936769127846, 0.05790088325738907, 0.0, 0.0, 0.0], [0.6849910020828247, 0.12280681729316711, 0.04972028359770775, 0.14248184859752655, 0.0, 0.0], [0.6015853881835938, 0.09881892055273056, 0.07070116698741913, 0.1665254533290863, 0.062369052320718765, 0.0], [0.32325053215026855, 0.12567415833473206, 0.04432179033756256, 0.07076980173587799, 0.06606654077768326, 0.3699170649051666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191646575927734, 0.08083534240722656, 0.0, 0.0, 0.0, 0.0], [0.4598640501499176, 0.39703115820884705, 0.14310480654239655, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181734442710876, 0.3816152513027191, 0.09618015587329865, 0.0, 0.0], [0.18963924050331116, 0.13763725757598877, 0.20173496007919312, 0.2363216131925583, 0.2346668690443039, 0.0], [0.15410453081130981, 0.09489504247903824, 0.11902561038732529, 0.1027795746922493, 0.4317219853401184, 0.09747327864170074]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.364999920129776, 0.6350001096725464, 0.0, 0.0, 0.0, 0.0], [0.24595212936401367, 0.5519201755523682, 0.20212772488594055, 0.0, 0.0, 0.0], [0.27213579416275024, 0.40738630294799805, 0.251862108707428, 0.06861570477485657, 0.0, 0.0], [0.1024254709482193, 0.16683608293533325, 0.5248051881790161, 0.05445462465286255, 0.15147872269153595, 0.0], [0.2502949833869934, 0.22198131680488586, 0.1889997124671936, 0.10677109658718109, 0.1303267925977707, 0.10162606090307236]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.300949364900589, 0.0, 0.0, 0.0, 0.0], [0.5107942819595337, 0.294864296913147, 0.1943414956331253, 0.0, 0.0, 0.0], [0.46047067642211914, 0.28051918745040894, 0.19174796342849731, 0.06726215779781342, 0.0, 0.0], [0.3764842748641968, 0.21120664477348328, 0.20214536786079407, 0.10207021236419678, 0.10809348523616791, 0.0], [0.30138450860977173, 0.20456179976463318, 0.1825033277273178, 0.11019382625818253, 0.16291265189647675, 0.03844384104013443]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.713158369064331, 0.28684163093566895, 0.0, 0.0, 0.0, 0.0], [0.4058799147605896, 0.18063293397426605, 0.41348710656166077, 0.0, 0.0, 0.0], [0.26554614305496216, 0.16985861957073212, 0.3358593285083771, 0.22873590886592865, 0.0, 0.0], [0.31385400891304016, 0.1831670105457306, 0.14928355813026428, 0.05377669632434845, 0.2999187409877777, 0.0], [0.20466554164886475, 0.18731112778186798, 0.15959149599075317, 0.06381770968437195, 0.03642303869128227, 0.3481910526752472]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242318153381, 0.34137576818466187, 0.0, 0.0, 0.0, 0.0], [0.5917777419090271, 0.3160034716129303, 0.09221877157688141, 0.0, 0.0, 0.0], [0.5477151870727539, 0.23586955666542053, 0.06145601347088814, 0.15495926141738892, 0.0, 0.0], [0.4587061107158661, 0.22439998388290405, 0.07887422293424606, 0.0992034301161766, 0.13881628215312958, 0.0], [0.32743728160858154, 0.19600822031497955, 0.06805708259344101, 0.0892510712146759, 0.11618075519800186, 0.20306557416915894]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448390550911427, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906113028526306, 0.07145342975854874, 0.0, 0.0, 0.0], [0.3800053596496582, 0.04127567261457443, 0.5496612191200256, 0.029057808220386505, 0.0, 0.0], [0.21445205807685852, 0.050887417048215866, 0.43174412846565247, 0.25869303941726685, 0.04422337934374809, 0.0], [0.11175268143415451, 0.01759307272732258, 0.027507441118359566, 0.04086774215102196, 0.7754669785499573, 0.02681216411292553]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285967946052551, 0.07140323519706726, 0.0, 0.0, 0.0, 0.0], [0.6077285408973694, 0.31214284896850586, 0.08012856543064117, 0.0, 0.0, 0.0], [0.49429091811180115, 0.2850370407104492, 0.11849313229322433, 0.1021789088845253, 0.0, 0.0], [0.41838788986206055, 0.2311791181564331, 0.08340615779161453, 0.11365945637226105, 0.1533673107624054, 0.0], [0.4221586287021637, 0.1291714906692505, 0.08740919828414917, 0.10163754224777222, 0.21230259537696838, 0.04732052609324455]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786475896835327, 0.02135237492620945, 0.0, 0.0, 0.0, 0.0], [0.7749121189117432, 0.0651036873459816, 0.15998415648937225, 0.0, 0.0, 0.0], [0.6484923958778381, 0.07483129948377609, 0.14751604199409485, 0.12916021049022675, 0.0, 0.0], [0.5224636793136597, 0.06921812891960144, 0.13823404908180237, 0.11106594651937485, 0.15901818871498108, 0.0], [0.39645177125930786, 0.07325821369886398, 0.1293814778327942, 0.10642431676387787, 0.14864003658294678, 0.14584419131278992]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525906085968018, 0.44740942120552063, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259309053421, 0.22387315332889557, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964668989181519, 0.1549196094274521, 0.1711207777261734, 0.0, 0.0], [0.5039963126182556, 0.11401881277561188, 0.11974020302295685, 0.12552586197853088, 0.13671880960464478, 0.0], [0.5061841607093811, 0.08567394316196442, 0.0890301838517189, 0.09759820997714996, 0.1027572825551033, 0.11875618249177933]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257424235343933, 0.07932537794113159, 0.0949321910738945, 0.0, 0.0, 0.0], [0.7306379675865173, 0.08571833372116089, 0.08043932169675827, 0.1032044067978859, 0.0, 0.0], [0.6383240818977356, 0.07886383682489395, 0.07815023511648178, 0.08758097141981125, 0.117080919444561, 0.0], [0.5552157163619995, 0.07409115880727768, 0.06834889203310013, 0.07778602838516235, 0.09999320656061172, 0.12456496059894562]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578913807868958, 0.14210855960845947, 0.0, 0.0, 0.0, 0.0], [0.6423036456108093, 0.16629023849964142, 0.19140605628490448, 0.0, 0.0, 0.0], [0.5530978441238403, 0.10609277337789536, 0.07821263372898102, 0.2625967860221863, 0.0, 0.0], [0.4012168049812317, 0.1222359910607338, 0.19347327947616577, 0.14164631068706512, 0.14142754673957825, 0.0], [0.40212583541870117, 0.1845075935125351, 0.07516805827617645, 0.058490391820669174, 0.14446339011192322, 0.13524475693702698]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844046026468277, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.062332455068826675, 0.05468333512544632, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617087453603745, 0.07321774214506149, 0.030065858736634254, 0.0, 0.0], [0.6819811463356018, 0.04990815743803978, 0.08296556025743484, 0.08369529247283936, 0.10144980996847153, 0.0], [0.4056687355041504, 0.07337656617164612, 0.08601398020982742, 0.06170930340886116, 0.13226443529129028, 0.24096696078777313]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670192003250122, 0.03298087790608406, 0.0, 0.0, 0.0, 0.0], [0.8449065089225769, 0.08514498919248581, 0.06994851678609848, 0.0, 0.0, 0.0], [0.7123571038246155, 0.07896049320697784, 0.055410757660865784, 0.1532716304063797, 0.0, 0.0], [0.640261173248291, 0.0739755630493164, 0.044393062591552734, 0.14322136342525482, 0.09814884513616562, 0.0], [0.5073902606964111, 0.07523062080144882, 0.07754648476839066, 0.11362482607364655, 0.13947948813438416, 0.08672824501991272]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487567901611328, 0.15124322474002838, 0.0, 0.0, 0.0, 0.0], [0.8415648341178894, 0.1210724338889122, 0.03736277297139168, 0.0, 0.0, 0.0], [0.7505517601966858, 0.11348951607942581, 0.061799556016922, 0.07415911555290222, 0.0, 0.0], [0.6614715456962585, 0.10242648422718048, 0.052934277802705765, 0.0752972960472107, 0.10787033289670944, 0.0], [0.6014202237129211, 0.11340402066707611, 0.05631927400827408, 0.07096727937459946, 0.10906262695789337, 0.04882659390568733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9445484280586243, 0.05545159429311752, 0.0, 0.0, 0.0, 0.0], [0.8874567747116089, 0.05474221706390381, 0.057801052927970886, 0.0, 0.0, 0.0], [0.8281887769699097, 0.06895007193088531, 0.05903473123908043, 0.04382641240954399, 0.0, 0.0], [0.6429893970489502, 0.06747540831565857, 0.11629702895879745, 0.05417948588728905, 0.11905863881111145, 0.0], [0.7367823123931885, 0.056119006127119064, 0.06857286393642426, 0.034219563007354736, 0.07875377684831619, 0.025552386417984962]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913392090704292, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981202797964215, 0.5288337469100952, 0.4703681766986847, 0.0, 0.0, 0.0], [0.0007648473256267607, 0.3451983630657196, 0.3085266649723053, 0.3455101251602173, 0.0, 0.0], [0.0010283150477334857, 0.24135911464691162, 0.23320142924785614, 0.2555714249610901, 0.26883965730667114, 0.0], [0.0009746808791533113, 0.17789694666862488, 0.1674315482378006, 0.18587610125541687, 0.18734434247016907, 0.2804763615131378]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8244927525520325, 0.17550718784332275, 0.0, 0.0, 0.0, 0.0], [0.12386851012706757, 0.044499825686216354, 0.8316316604614258, 0.0, 0.0, 0.0], [0.07924355566501617, 0.012965913861989975, 0.0015277150087058544, 0.9062628149986267, 0.0, 0.0], [0.08806417882442474, 0.02134108357131481, 0.0028886189684271812, 0.002845388138666749, 0.8848607540130615, 0.0], [0.09983226656913757, 0.03363394737243652, 0.005499998107552528, 0.00243305298499763, 0.0015082467580214143, 0.8570924997329712]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531072288751602, 0.0, 0.0, 0.0, 0.0], [0.7529155015945435, 0.08733480423688889, 0.15974965691566467, 0.0, 0.0, 0.0], [0.42022842168807983, 0.09195113927125931, 0.23549841344356537, 0.25232207775115967, 0.0, 0.0], [0.3084895610809326, 0.05908143147826195, 0.3839128613471985, 0.15659146010875702, 0.09192463010549545, 0.0], [0.447904109954834, 0.04329312965273857, 0.07969177514314651, 0.1108192726969719, 0.2212459146976471, 0.09704578667879105]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904017508029938, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.026084477081894875, 0.004147926811128855, 0.0, 0.0, 0.0], [0.9082902073860168, 0.03320597484707832, 0.009421153925359249, 0.04908263683319092, 0.0, 0.0], [0.8949136137962341, 0.055445361882448196, 0.005577605217695236, 0.03150679171085358, 0.012556544505059719, 0.0], [0.8497737050056458, 0.028890114277601242, 0.0036648025270551443, 0.03751996532082558, 0.038428016006946564, 0.041723549365997314]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474484534934163, 0.0, 0.0, 0.0, 0.0], [0.4894773066043854, 0.48122045397758484, 0.02930225059390068, 0.0, 0.0, 0.0], [0.11772146075963974, 0.13121247291564941, 0.67023104429245, 0.08083496242761612, 0.0, 0.0], [0.13043726980686188, 0.0406869612634182, 0.2652043104171753, 0.41143471002578735, 0.15223680436611176, 0.0], [0.12661851942539215, 0.03275134041905403, 0.03567883372306824, 0.06039177253842354, 0.6021823287010193, 0.14237718284130096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.019482314586639404, 0.0, 0.0, 0.0, 0.0], [0.7948848009109497, 0.12061930447816849, 0.0844959020614624, 0.0, 0.0, 0.0], [0.5612354874610901, 0.15743164718151093, 0.2033972144126892, 0.07793562114238739, 0.0, 0.0], [0.4258382320404053, 0.10742025077342987, 0.15123654901981354, 0.08754990994930267, 0.22795499861240387, 0.0], [0.24752630293369293, 0.024188317358493805, 0.030395260080695152, 0.08586960285902023, 0.5714336633682251, 0.04058684781193733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223198845982552, 0.0, 0.0, 0.0, 0.0], [0.7572691440582275, 0.22317387163639069, 0.0195570457726717, 0.0, 0.0, 0.0], [0.5341880321502686, 0.22107607126235962, 0.17621813714504242, 0.0685177892446518, 0.0, 0.0], [0.17095306515693665, 0.08229431509971619, 0.5760217905044556, 0.11097602546215057, 0.0597548633813858, 0.0], [0.2487107813358307, 0.08880821615457535, 0.08980182558298111, 0.09729332476854324, 0.4413091838359833, 0.03407657518982887]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.84221351146698, 0.1577865481376648, 0.0, 0.0, 0.0, 0.0], [0.46841251850128174, 0.4610540270805359, 0.07053346186876297, 0.0, 0.0, 0.0], [0.25881412625312805, 0.46358928084373474, 0.18503478169441223, 0.09256181120872498, 0.0, 0.0], [0.18399572372436523, 0.29154250025749207, 0.17031069099903107, 0.2717295289039612, 0.08242153376340866, 0.0], [0.16469858586788177, 0.24727003276348114, 0.08770552277565002, 0.2257496416568756, 0.1774536818265915, 0.09712250530719757]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005395531654358, 0.0, 0.0, 0.0, 0.0], [0.9068723320960999, 0.044065166264772415, 0.049062490463256836, 0.0, 0.0, 0.0], [0.8582221865653992, 0.055348340421915054, 0.040419381111860275, 0.046010058373212814, 0.0, 0.0], [0.7855251431465149, 0.041242457926273346, 0.08369290828704834, 0.04887617751955986, 0.04066329449415207, 0.0], [0.7856318354606628, 0.0501464419066906, 0.04751264303922653, 0.027365924790501595, 0.0561474971473217, 0.03319565951824188]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041034579277039, 0.09589655697345734, 0.0, 0.0, 0.0, 0.0], [0.5862311720848083, 0.07199837267398834, 0.3417704999446869, 0.0, 0.0, 0.0], [0.38789618015289307, 0.046608004719018936, 0.20278996229171753, 0.36270585656166077, 0.0, 0.0], [0.2665242850780487, 0.02453301101922989, 0.12211935967206955, 0.20041202008724213, 0.3864113688468933, 0.0], [0.2335740178823471, 0.020537324249744415, 0.09610337764024734, 0.13062253594398499, 0.2299049347639084, 0.28925779461860657]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.03600878641009331, 0.0, 0.0, 0.0, 0.0], [0.7075549960136414, 0.25427794456481934, 0.03816710785031319, 0.0, 0.0, 0.0], [0.25665247440338135, 0.2058933526277542, 0.016656633466482162, 0.520797610282898, 0.0, 0.0], [0.10379401594400406, 0.04639105498790741, 0.00869862549006939, 0.7866847515106201, 0.05443162843585014, 0.0], [0.22143346071243286, 0.033797502517700195, 0.029023950919508934, 0.541292130947113, 0.15286119282245636, 0.0215916745364666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829640552401543, 0.0, 0.0, 0.0, 0.0], [0.7913153767585754, 0.12309644371271133, 0.08558813482522964, 0.0, 0.0, 0.0], [0.2954603135585785, 0.15808317065238953, 0.4217239022254944, 0.12473267316818237, 0.0, 0.0], [0.23441052436828613, 0.09886535257101059, 0.33160147070884705, 0.19713923335075378, 0.13798339664936066, 0.0], [0.19728368520736694, 0.05741846561431885, 0.06909020990133286, 0.1646982580423355, 0.2797277271747589, 0.2317817062139511]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.06408718228340149, 0.0, 0.0, 0.0, 0.0], [0.7888625860214233, 0.0867348238825798, 0.12440251559019089, 0.0, 0.0, 0.0], [0.6535119414329529, 0.07573550939559937, 0.09732570499181747, 0.17342683672904968, 0.0, 0.0], [0.5222766995429993, 0.05827884376049042, 0.09920478612184525, 0.1702084094285965, 0.15003129839897156, 0.0], [0.4108838438987732, 0.047306086868047714, 0.07265683263540268, 0.10560749471187592, 0.10550011694431305, 0.25804561376571655]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683831930160522, 0.031616728752851486, 0.0, 0.0, 0.0, 0.0], [0.896539568901062, 0.03887060284614563, 0.06458979845046997, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213466331362724, 0.051967162638902664, 0.08940286934375763, 0.0, 0.0], [0.7718175053596497, 0.030402861535549164, 0.04582742601633072, 0.07118464261293411, 0.08076757192611694, 0.0], [0.7292331457138062, 0.021699873730540276, 0.033074744045734406, 0.04720093309879303, 0.06474556028842926, 0.10404572635889053]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.0020432821474969387, 0.0, 0.0, 0.0, 0.0], [0.9552940726280212, 0.008025333285331726, 0.03668065741658211, 0.0, 0.0, 0.0], [0.9254711270332336, 0.00275557953864336, 0.002062988467514515, 0.06971034407615662, 0.0, 0.0], [0.8660575151443481, 0.003888372564688325, 0.0006785987643525004, 0.0006981458282098174, 0.12867732346057892, 0.0], [0.8455936908721924, 0.0037804015446454287, 0.0002534226223360747, 6.0270347603363916e-05, 0.00011820702638942748, 0.150193989276886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262455701828003, 0.07375437766313553, 0.0, 0.0, 0.0, 0.0], [0.7717147469520569, 0.1624203771352768, 0.06586486846208572, 0.0, 0.0, 0.0], [0.8167640566825867, 0.07807155698537827, 0.06324019283056259, 0.04192415252327919, 0.0, 0.0], [0.6867176294326782, 0.07755190879106522, 0.1005692109465599, 0.05955103039741516, 0.07561030983924866, 0.0], [0.6421176791191101, 0.11014875024557114, 0.07688140124082565, 0.05403309315443039, 0.1033359244465828, 0.013483130373060703]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395952820777893, 0.06040477007627487, 0.0, 0.0, 0.0, 0.0], [0.2300449162721634, 0.6617392301559448, 0.10821589082479477, 0.0, 0.0, 0.0], [0.26702260971069336, 0.3607953190803528, 0.3249623775482178, 0.04721971973776817, 0.0, 0.0], [0.5952032804489136, 0.12269210070371628, 0.06302005052566528, 0.08916770666837692, 0.12991684675216675, 0.0], [0.1028466448187828, 0.029380010440945625, 0.01373895350843668, 0.04586036503314972, 0.7698498964309692, 0.03832418471574783]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040982723236084, 0.0959017425775528, 0.0, 0.0, 0.0, 0.0], [0.357235312461853, 0.6274638175964355, 0.015300935134291649, 0.0, 0.0, 0.0], [0.5918000936508179, 0.27640387415885925, 0.1047603040933609, 0.027035744860768318, 0.0, 0.0], [0.7254436612129211, 0.04983079805970192, 0.01498265191912651, 0.17781229317188263, 0.03193056955933571, 0.0], [0.7612767219543457, 0.06158901005983353, 0.005942164920270443, 0.01642669551074505, 0.12677954137325287, 0.02798592671751976]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.005241230130195618, 0.0, 0.0, 0.0, 0.0], [0.9632415771484375, 0.017816435545682907, 0.018942005932331085, 0.0, 0.0, 0.0], [0.9671075940132141, 0.008509604260325432, 0.00856224074959755, 0.015820497646927834, 0.0, 0.0], [0.9340998530387878, 0.011952383443713188, 0.020180154591798782, 0.026750771328806877, 0.007016891613602638, 0.0], [0.9587240219116211, 0.0046570925042033195, 0.003326763864606619, 0.006545269396156073, 0.010182411409914494, 0.016564475372433662]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.02300085686147213, 0.0, 0.0, 0.0, 0.0], [0.791760265827179, 0.1753326654434204, 0.032907143235206604, 0.0, 0.0, 0.0], [0.7949190735816956, 0.10531850159168243, 0.04021850973367691, 0.05954388156533241, 0.0, 0.0], [0.7097727060317993, 0.10552525520324707, 0.06597540527582169, 0.05765572935342789, 0.06107088923454285, 0.0], [0.7506603598594666, 0.026514418423175812, 0.02157600037753582, 0.034296635538339615, 0.08494450896978378, 0.08200804889202118]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.01624833419919014, 0.0, 0.0, 0.0, 0.0], [0.5615487694740295, 0.08956838399171829, 0.3488827645778656, 0.0, 0.0, 0.0], [0.3292914927005768, 0.024114832282066345, 0.5428048968315125, 0.10378878563642502, 0.0, 0.0], [0.34330493211746216, 0.013086404651403427, 0.5121950507164001, 0.11146263778209686, 0.01995093934237957, 0.0], [0.4792822599411011, 0.017333481460809708, 0.11805278062820435, 0.06130271032452583, 0.20071901381015778, 0.12330969423055649]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115317836403847, 0.0, 0.0, 0.0, 0.0], [0.5282679200172424, 0.3292284309864044, 0.14250363409519196, 0.0, 0.0, 0.0], [0.48788732290267944, 0.233686164021492, 0.17577986419200897, 0.10264668613672256, 0.0, 0.0], [0.31444936990737915, 0.18065084517002106, 0.16871292889118195, 0.09506543725728989, 0.24112139642238617, 0.0], [0.5168782472610474, 0.03589695692062378, 0.026187807321548462, 0.040397077798843384, 0.18791691958904266, 0.19272294640541077]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750306367874146, 0.12496936321258545, 0.0, 0.0, 0.0, 0.0], [0.4550616145133972, 0.4900423586368561, 0.05489595979452133, 0.0, 0.0, 0.0], [0.29337263107299805, 0.5449898838996887, 0.09444298595190048, 0.06719449907541275, 0.0, 0.0], [0.4897097647190094, 0.2720980942249298, 0.06861936300992966, 0.14694873988628387, 0.02262401394546032, 0.0], [0.4729084074497223, 0.08103056997060776, 0.01605204865336418, 0.3067218065261841, 0.10120705515146255, 0.022080253809690475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697795420885086, 0.0, 0.0, 0.0, 0.0], [0.7557179927825928, 0.1643647700548172, 0.07991719990968704, 0.0, 0.0, 0.0], [0.6947709918022156, 0.08409848809242249, 0.06382585316896439, 0.15730471909046173, 0.0, 0.0], [0.5821163654327393, 0.03297785297036171, 0.07936536520719528, 0.1944136917591095, 0.11112680286169052, 0.0], [0.5974539518356323, 0.04261082038283348, 0.06919696182012558, 0.14563480019569397, 0.12481768429279327, 0.02028587833046913]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217814654111862, 0.0, 0.0, 0.0, 0.0], [0.9312829971313477, 0.010560262948274612, 0.058156777173280716, 0.0, 0.0, 0.0], [0.8435326218605042, 0.015694990754127502, 0.045751187950372696, 0.09502114355564117, 0.0, 0.0], [0.7724104523658752, 0.011981194838881493, 0.035046011209487915, 0.038767579942941666, 0.14179480075836182, 0.0], [0.7642906904220581, 0.00986877828836441, 0.008122753351926804, 0.013314371928572655, 0.04824399948120117, 0.15615928173065186]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701175093650818, 0.029882490634918213, 0.0, 0.0, 0.0, 0.0], [0.6563995480537415, 0.22506217658519745, 0.11853817850351334, 0.0, 0.0, 0.0], [0.6958061456680298, 0.1470184177160263, 0.07145984470844269, 0.08571554720401764, 0.0, 0.0], [0.6353272795677185, 0.13460662961006165, 0.030994117259979248, 0.05691640451550484, 0.1421555131673813, 0.0], [0.6779407262802124, 0.05365397781133652, 0.018006201833486557, 0.06284506618976593, 0.11038198322057724, 0.07717210799455643]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822332859039307, 0.01776670478284359, 0.0, 0.0, 0.0, 0.0], [0.9037660956382751, 0.06541543453931808, 0.030818426981568336, 0.0, 0.0, 0.0], [0.8119187355041504, 0.036790236830711365, 0.06056087091565132, 0.09073004871606827, 0.0, 0.0], [0.40546342730522156, 0.10383892804384232, 0.10211260616779327, 0.3543427288532257, 0.03424236178398132, 0.0], [0.22824503481388092, 0.017278604209423065, 0.05055435746908188, 0.6015732288360596, 0.09411737322807312, 0.008231470361351967]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685154564678669, 0.0, 0.0, 0.0, 0.0], [0.354457825422287, 0.531760036945343, 0.11378218978643417, 0.0, 0.0, 0.0], [0.07823401689529419, 0.7221351265907288, 0.10936620831489563, 0.09026475995779037, 0.0, 0.0], [0.21968045830726624, 0.40484222769737244, 0.1235806941986084, 0.2001885175704956, 0.051708124577999115, 0.0], [0.36089763045310974, 0.1045902818441391, 0.06983798742294312, 0.29764822125434875, 0.13869896531105042, 0.028326835483312607]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732161164283752, 0.026783881708979607, 0.0, 0.0, 0.0, 0.0], [0.9167553782463074, 0.06145283579826355, 0.02179183065891266, 0.0, 0.0, 0.0], [0.8543079495429993, 0.08049621433019638, 0.03033490665256977, 0.03486097976565361, 0.0, 0.0], [0.8919220566749573, 0.04280766472220421, 0.022044911980628967, 0.023470569401979446, 0.01975482702255249, 0.0], [0.8116769194602966, 0.03413527458906174, 0.03567648306488991, 0.04748578742146492, 0.025397121906280518, 0.045628443360328674]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761363983154, 0.04972386732697487, 0.0, 0.0, 0.0, 0.0], [0.7637453675270081, 0.20073619484901428, 0.03551839664578438, 0.0, 0.0, 0.0], [0.6279090046882629, 0.037681419402360916, 0.19945412874221802, 0.13495545089244843, 0.0, 0.0], [0.6397066712379456, 0.027007192373275757, 0.09081999957561493, 0.20653821527957916, 0.03592786192893982, 0.0], [0.45594266057014465, 0.02164124697446823, 0.12939591705799103, 0.21800900995731354, 0.10379799455404282, 0.07121305912733078]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498405456542969, 0.05015944689512253, 0.0, 0.0, 0.0, 0.0], [0.868872344493866, 0.08722198009490967, 0.04390567168593407, 0.0, 0.0, 0.0], [0.6937950849533081, 0.06359203159809113, 0.09179060161113739, 0.1508222371339798, 0.0, 0.0], [0.7266592383384705, 0.04389891028404236, 0.046839818358421326, 0.09851827472448349, 0.08408384770154953, 0.0], [0.7848992943763733, 0.037147846072912216, 0.012907843105494976, 0.010539384558796883, 0.12079204618930817, 0.03371358662843704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.01089461799710989, 0.0, 0.0, 0.0, 0.0], [0.8929510116577148, 0.08700131624937057, 0.020047729834914207, 0.0, 0.0, 0.0], [0.7891115546226501, 0.09797312319278717, 0.0863322764635086, 0.026583032682538033, 0.0, 0.0], [0.8850637674331665, 0.0364501029253006, 0.053954314440488815, 0.012377242557704449, 0.01215458381921053, 0.0], [0.6861329078674316, 0.057203810662031174, 0.0116362813860178, 0.02166050672531128, 0.17488020658493042, 0.048486314713954926]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396193027496338, 0.06038068234920502, 0.0, 0.0, 0.0, 0.0], [0.7851802110671997, 0.19751375913619995, 0.01730601117014885, 0.0, 0.0, 0.0], [0.7660512328147888, 0.15444660186767578, 0.0318828783929348, 0.04761931300163269, 0.0, 0.0], [0.7035237550735474, 0.05171409994363785, 0.0776095986366272, 0.15339010953903198, 0.013762442395091057, 0.0], [0.7121893763542175, 0.04994220659136772, 0.03772540017962456, 0.08649095147848129, 0.06541402637958527, 0.04823804274201393]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927739217877388, 0.0, 0.0, 0.0, 0.0], [0.7925394773483276, 0.011715609580278397, 0.19574493169784546, 0.0, 0.0, 0.0], [0.5106772184371948, 0.007296781521290541, 0.03962003067135811, 0.44240593910217285, 0.0, 0.0], [0.5862484574317932, 0.01209966279566288, 0.024585144594311714, 0.06737807393074036, 0.30968865752220154, 0.0], [0.3019636273384094, 0.007724008988589048, 0.011518117040395737, 0.04694722592830658, 0.2214670479297638, 0.41037997603416443]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.02554461918771267, 0.0, 0.0, 0.0, 0.0], [0.9769195318222046, 0.015048524364829063, 0.00803192425519228, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875424966216087, 0.02595478855073452, 0.04210774973034859, 0.0, 0.0], [0.9400084614753723, 0.00555663276463747, 0.005828281864523888, 0.031757764518260956, 0.016849050298333168, 0.0], [0.9105738401412964, 0.0019752182997763157, 0.008646713569760323, 0.013360859826207161, 0.03543969988822937, 0.030003685504198074]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.02083336003124714, 0.0, 0.0, 0.0, 0.0], [0.8444863557815552, 0.13507835566997528, 0.020435357466340065, 0.0, 0.0, 0.0], [0.7903085947036743, 0.14559166133403778, 0.037530042231082916, 0.026569712907075882, 0.0, 0.0], [0.7298934459686279, 0.05649632588028908, 0.03273547440767288, 0.10400423407554626, 0.07687054574489594, 0.0], [0.5684199929237366, 0.04388810321688652, 0.026293331757187843, 0.08117101341485977, 0.2431478202342987, 0.037079744040966034]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.050013184547424316, 0.0, 0.0, 0.0, 0.0], [0.9336171746253967, 0.05848868191242218, 0.007894255220890045, 0.0, 0.0, 0.0], [0.7897834181785583, 0.11071813106536865, 0.05360180512070656, 0.045896656811237335, 0.0, 0.0], [0.8859304785728455, 0.05752970278263092, 0.013743232935667038, 0.0033877352252602577, 0.03940894827246666, 0.0], [0.9337607622146606, 0.026470666751265526, 0.004523405339568853, 0.0061904969625175, 0.01413296815007925, 0.014921738766133785]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521648659231005e-09, 0.0, 0.0, 0.0, 0.0], [6.6758143475453835e-06, 0.9999804496765137, 1.284119480260415e-05, 0.0, 0.0, 0.0], [2.219406880499264e-08, 2.668508969350114e-09, 0.9999971389770508, 2.813725814121426e-06, 0.0, 0.0], [1.0145217856916133e-06, 4.4640319885047575e-08, 0.0003535518771968782, 0.9993677735328674, 0.00027762516401708126, 0.0], [9.436730286083161e-10, 1.3820468207359493e-11, 5.017710691390675e-10, 2.9652009736480522e-09, 0.9999971389770508, 2.864445150407846e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.00513678602874279, 0.0, 0.0, 0.0, 0.0], [0.9274216890335083, 0.018323812633752823, 0.05425459146499634, 0.0, 0.0, 0.0], [0.9678993225097656, 0.0041434201411902905, 0.004314461722970009, 0.023642871528863907, 0.0, 0.0], [0.899907648563385, 0.0014671608805656433, 0.00029133600764907897, 0.002585014561191201, 0.09574881941080093, 0.0], [0.9386116862297058, 0.00022248241293709725, 0.000614665390457958, 0.0015495705883949995, 0.030689310282468796, 0.02831241302192211]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042735781695228e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613615985610522e-06, 0.001720665255561471, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376233727678482e-07, 0.00011847116547869518, 0.0, 0.0], [0.9996154308319092, 3.4731792197817413e-07, 3.892067468314053e-08, 4.468433303372876e-07, 0.00038369561661966145, 0.0], [0.9994840621948242, 1.6550142589721872e-08, 2.871539450666205e-08, 1.0638284493325045e-06, 0.00021266516705509275, 0.0003021192387677729]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.048586443066596985, 0.0, 0.0, 0.0, 0.0], [0.5749930143356323, 0.39028263092041016, 0.03472428396344185, 0.0, 0.0, 0.0], [0.744231641292572, 0.1752413809299469, 0.07564764469861984, 0.004879307933151722, 0.0, 0.0], [0.5232048034667969, 0.09429354965686798, 0.11381909251213074, 0.199794739484787, 0.06888782978057861, 0.0], [0.4747248888015747, 0.05636602267622948, 0.045303650200366974, 0.06967318058013916, 0.3098025918006897, 0.044129688292741776]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734647631645203, 0.12653520703315735, 0.0, 0.0, 0.0, 0.0], [0.6097909212112427, 0.3541729748249054, 0.03603604808449745, 0.0, 0.0, 0.0], [0.4598419666290283, 0.3869785964488983, 0.09960105270147324, 0.05357832461595535, 0.0, 0.0], [0.5722200274467468, 0.23636257648468018, 0.08344569057226181, 0.06921947747468948, 0.038752224296331406, 0.0], [0.514358401298523, 0.16722990572452545, 0.09019368141889572, 0.0765446200966835, 0.10578057914972305, 0.045892804861068726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771234899759293, 0.0, 0.0, 0.0, 0.0], [0.6142938137054443, 0.35039809346199036, 0.03530815243721008, 0.0, 0.0, 0.0], [0.5770687460899353, 0.32858437299728394, 0.05508258566260338, 0.03926431015133858, 0.0, 0.0], [0.17188090085983276, 0.011042523197829723, 0.05457884445786476, 0.7326592803001404, 0.02983849309384823, 0.0], [0.3783024251461029, 0.017070062458515167, 0.021754097193479538, 0.4409683644771576, 0.06093815341591835, 0.08096696436405182]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688735146075487, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.016709759831428528, 0.033411506563425064, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787286351434886, 0.0006868178606964648, 0.002304842695593834, 0.0, 0.0], [0.9935757517814636, 0.003263507504016161, 0.0009993839776143432, 0.0002793238090816885, 0.001882061013020575, 0.0], [0.9907532930374146, 0.00021344359265640378, 0.0004595248610712588, 0.0007905631209723651, 0.004424731712788343, 0.003358363639563322]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9647740125656128, 0.03522596135735512, 0.0, 0.0, 0.0, 0.0], [0.8194130659103394, 0.1365436464548111, 0.044043250381946564, 0.0, 0.0, 0.0], [0.7584242820739746, 0.006878956686705351, 0.20653414726257324, 0.028162650763988495, 0.0, 0.0], [0.5298121571540833, 0.002678812248632312, 0.07857993245124817, 0.3598378598690033, 0.029091132804751396, 0.0], [0.754442572593689, 0.0003678239299915731, 0.001971345627680421, 0.003240057732909918, 0.19423308968544006, 0.04574507102370262]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749132394790649, 0.025086797773838043, 0.0, 0.0, 0.0, 0.0], [0.9306469559669495, 0.057056792080402374, 0.012296278029680252, 0.0, 0.0, 0.0], [0.9305251836776733, 0.05277099460363388, 0.011119411326944828, 0.005584418307989836, 0.0, 0.0], [0.8863323926925659, 0.012924155220389366, 0.017724651843309402, 0.06150183826684952, 0.021517043933272362, 0.0], [0.7916852831840515, 0.015036062337458134, 0.031747858971357346, 0.033922016620635986, 0.03707969933748245, 0.09052912145853043]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.960849940776825, 0.039150021970272064, 0.0, 0.0, 0.0, 0.0], [0.9121273159980774, 0.022576453164219856, 0.06529619544744492, 0.0, 0.0, 0.0], [0.9364106059074402, 0.01558446604758501, 0.024544961750507355, 0.023459969088435173, 0.0, 0.0], [0.9454619288444519, 0.006762297358363867, 0.022026164457201958, 0.009137828834354877, 0.0166118573397398, 0.0], [0.8346167802810669, 0.0018816972151398659, 0.005609032232314348, 0.01887362077832222, 0.1244916245341301, 0.014527121558785439]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.003577286144718528, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453043937683105, 0.004154064226895571, 0.0, 0.0, 0.0], [0.9735792279243469, 0.01900341734290123, 0.0036644143983721733, 0.003752920078113675, 0.0, 0.0], [0.9586310982704163, 0.007116200402379036, 0.009218422695994377, 0.02272571064531803, 0.0023084881249815226, 0.0], [0.973607063293457, 0.008490582928061485, 0.0032512503676116467, 0.0036064486484974623, 0.004877470899373293, 0.006167230196297169]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024012047797441483, 0.0, 0.0, 0.0, 0.0], [0.946063756942749, 0.04211379587650299, 0.011822430416941643, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293113946914673, 0.05218193307518959, 0.0602056086063385, 0.0, 0.0], [0.9378372430801392, 0.03354857116937637, 0.008826462551951408, 0.0028792363591492176, 0.016908491030335426, 0.0], [0.8124933838844299, 0.026967575773596764, 0.05999194458127022, 0.03445727750658989, 0.011011868715286255, 0.05507809296250343]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001206755638123, 0.09987929463386536, 0.0, 0.0, 0.0, 0.0], [0.6271925568580627, 0.07988723367452621, 0.2929201126098633, 0.0, 0.0, 0.0], [0.7624078989028931, 0.02734428085386753, 0.03867945075035095, 0.17156831920146942, 0.0, 0.0], [0.7995962500572205, 0.014336277730762959, 0.014375667087733746, 0.025438543409109116, 0.1462532877922058, 0.0], [0.7851975560188293, 0.04204043000936508, 0.025253599509596825, 0.02908393368124962, 0.029306255280971527, 0.08911828696727753]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.004553207661956549, 0.0, 0.0, 0.0, 0.0], [0.9356004595756531, 0.04476727917790413, 0.019632209092378616, 0.0, 0.0, 0.0], [0.5605551600456238, 0.09862001240253448, 0.2998324930667877, 0.04099231958389282, 0.0, 0.0], [0.589370608329773, 0.1100098192691803, 0.08033646643161774, 0.16754046082496643, 0.0527426153421402, 0.0], [0.223059743642807, 0.056807976216077805, 0.05467941239476204, 0.24733929336071014, 0.3111240565776825, 0.10698945075273514]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301448464393616, 0.06985516101121902, 0.0, 0.0, 0.0, 0.0], [0.8936478495597839, 0.08535714447498322, 0.020995058119297028, 0.0, 0.0, 0.0], [0.8404536843299866, 0.10619213432073593, 0.023636789992451668, 0.029717300087213516, 0.0, 0.0], [0.8927381634712219, 0.02478480525314808, 0.008319051936268806, 0.05165467783808708, 0.022503303363919258, 0.0], [0.8646609783172607, 0.009503169916570187, 0.00243298034183681, 0.04796737805008888, 0.042732127010822296, 0.032703299075365067]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037402346730232, 0.0, 0.0, 0.0, 0.0], [0.9702038764953613, 0.01680702343583107, 0.012989096343517303, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064444556832314, 0.013456214219331741, 0.018002301454544067, 0.0, 0.0], [0.9332928657531738, 0.018971974030137062, 0.020146867260336876, 0.017023736611008644, 0.010564574971795082, 0.0], [0.9113593697547913, 0.012528610415756702, 0.022096145898103714, 0.017518552020192146, 0.01851789653301239, 0.01797933503985405]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182312101125717, 0.0, 0.0, 0.0, 0.0], [0.9096419215202332, 0.07916687428951263, 0.011191246099770069, 0.0, 0.0, 0.0], [0.8379933834075928, 0.13078251481056213, 0.012140998616814613, 0.019083019345998764, 0.0, 0.0], [0.9116523265838623, 0.05451972037553787, 0.00949938129633665, 0.007465865928679705, 0.016862763091921806, 0.0], [0.8510287404060364, 0.07338211685419083, 0.008022502064704895, 0.009083151817321777, 0.04261011257767677, 0.015873325988650322]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.02009769156575203, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.029063263908028603, 0.015062462538480759, 0.0, 0.0, 0.0], [0.7943130731582642, 0.06074107438325882, 0.0690767914056778, 0.0758691281080246, 0.0, 0.0], [0.549432098865509, 0.031547121703624725, 0.054820187389850616, 0.0578807033598423, 0.306319922208786, 0.0], [0.645397961139679, 0.010770927183330059, 0.017528077587485313, 0.02157982438802719, 0.24958311021327972, 0.05514014512300491]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506808519363403, 0.049319129437208176, 0.0, 0.0, 0.0, 0.0], [0.8553208708763123, 0.09256317466497421, 0.05211597681045532, 0.0, 0.0, 0.0], [0.8508525490760803, 0.04734596610069275, 0.04417724534869194, 0.057624202221632004, 0.0, 0.0], [0.7697128653526306, 0.027885887771844864, 0.031017253175377846, 0.06842502951622009, 0.10295900702476501, 0.0], [0.7931906580924988, 0.040521834045648575, 0.029241926968097687, 0.04478121176362038, 0.04894692823290825, 0.04331746697425842]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.022968946024775505, 0.0, 0.0, 0.0, 0.0], [0.9429818391799927, 0.017321474850177765, 0.03969673812389374, 0.0, 0.0, 0.0], [0.9144347906112671, 0.008583571761846542, 0.013035777024924755, 0.06394589692354202, 0.0, 0.0], [0.9222431182861328, 0.003644028678536415, 0.003740261774510145, 0.010410326533019543, 0.05996226519346237, 0.0], [0.9198879599571228, 0.0030822642147541046, 0.0034827410709112883, 0.0042068008333444595, 0.021254301071166992, 0.04808594286441803]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9774582386016846, 0.02254181168973446, 0.0, 0.0, 0.0, 0.0], [0.8929324150085449, 0.07475479692220688, 0.032312821596860886, 0.0, 0.0, 0.0], [0.8423513174057007, 0.05980277061462402, 0.037400756031274796, 0.060445044189691544, 0.0, 0.0], [0.7674633264541626, 0.035363439470529556, 0.04215509817004204, 0.06658629328012466, 0.08843192458152771, 0.0], [0.6182613372802734, 0.016110623255372047, 0.020167628303170204, 0.03868889808654785, 0.2314697951078415, 0.0753016546368599]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634856581687927, 0.036514345556497574, 0.0, 0.0, 0.0, 0.0], [0.43639448285102844, 0.5226364731788635, 0.040969014167785645, 0.0, 0.0, 0.0], [0.36086124181747437, 0.35129690170288086, 0.2655107080936432, 0.02233118563890457, 0.0, 0.0], [0.39429229497909546, 0.021704625338315964, 0.07794322818517685, 0.3716890215873718, 0.13437077403068542, 0.0], [0.6310721635818481, 0.016983957961201668, 0.025942014530301094, 0.08615921437740326, 0.21831963956356049, 0.021522965282201767]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750265257433057, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.0004826387739740312, 0.005030233412981033, 0.0, 0.0, 0.0], [0.9981209635734558, 2.7051630240748636e-05, 0.00011307397653581575, 0.0017389433924108744, 0.0, 0.0], [0.9982239603996277, 6.836584361735731e-05, 0.00010199935059063137, 6.028370262356475e-05, 0.001545313629321754, 0.0], [0.9982888102531433, 1.0552178082434693e-06, 3.278081203461625e-05, 0.0001303895260207355, 0.0006605856469832361, 0.0008863675757311285]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328933872282505, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561349716037512, 0.025375083088874817, 0.0, 0.0, 0.0], [0.9724301099777222, 0.00195861142128706, 0.011192452162504196, 0.014418844133615494, 0.0, 0.0], [0.9782041311264038, 0.0009589171386323869, 0.001870649284683168, 0.006326562725007534, 0.01263973768800497, 0.0], [0.9592596888542175, 0.002455513458698988, 0.0016124167013913393, 0.005019667558372021, 0.006687135435640812, 0.024965722113847733]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.03709990158677101, 0.0, 0.0, 0.0, 0.0], [0.36802080273628235, 0.6152244210243225, 0.016754813492298126, 0.0, 0.0, 0.0], [0.31735214591026306, 0.6140003800392151, 0.053751468658447266, 0.014896074309945107, 0.0, 0.0], [0.4898741543292999, 0.21071387827396393, 0.04693012312054634, 0.20700415968894958, 0.04547771066427231, 0.0], [0.48774242401123047, 0.1769523322582245, 0.06915220618247986, 0.09849317371845245, 0.12091425806283951, 0.04674568027257919]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.02055807039141655, 0.0, 0.0, 0.0, 0.0], [0.6677890419960022, 0.31032490730285645, 0.021886074915528297, 0.0, 0.0, 0.0], [0.711875855922699, 0.11108537018299103, 0.14187364280223846, 0.03516502305865288, 0.0, 0.0], [0.4501466155052185, 0.04036048427224159, 0.04045815393328667, 0.3885694742202759, 0.0804651752114296, 0.0], [0.49346205592155457, 0.013696958310902119, 0.00812679436057806, 0.13074517250061035, 0.30861401557922363, 0.04535504803061485]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394601970911026, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.007713806349784136, 0.011612341739237309, 0.0, 0.0, 0.0], [0.9326630234718323, 0.01957845874130726, 0.024103542789816856, 0.02365495264530182, 0.0, 0.0], [0.9422018527984619, 0.0009538960293866694, 0.0010898001492023468, 0.0031933635473251343, 0.05256103351712227, 0.0], [0.9352929592132568, 0.0010279365815222263, 0.004444439895451069, 0.0016371352830901742, 0.010590966790914536, 0.047006525099277496]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216770650818944, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178908171132207, 0.009547143243253231, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997050124686211e-05, 0.00013218825915828347, 0.0017900299280881882, 0.0, 0.0], [0.9986976385116577, 4.1044117097044364e-05, 3.868332441925304e-06, 2.3676169803366065e-05, 0.0012337109073996544, 0.0], [0.9971562623977661, 1.8522179743740708e-05, 1.8826593759513344e-06, 2.7900150598725304e-05, 0.0006533485138788819, 0.002141993958503008]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768233299255371, 0.023176709190011024, 0.0, 0.0, 0.0, 0.0], [0.919467568397522, 0.050882015377283096, 0.029650306329131126, 0.0, 0.0, 0.0], [0.8474555015563965, 0.06100171059370041, 0.04372366517782211, 0.047819141298532486, 0.0, 0.0], [0.8011622428894043, 0.041867081075906754, 0.04375801607966423, 0.041894808411598206, 0.07131782919168472, 0.0], [0.8031870126724243, 0.024504918605089188, 0.01732351817190647, 0.0474439337849617, 0.06109936535358429, 0.04644131660461426]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.01705716922879219, 0.0, 0.0, 0.0, 0.0], [0.8863736391067505, 0.09492656588554382, 0.018699748441576958, 0.0, 0.0, 0.0], [0.9231085777282715, 0.03696347773075104, 0.03219832852482796, 0.007729670964181423, 0.0, 0.0], [0.9068530201911926, 0.01604657620191574, 0.014310453087091446, 0.04543779417872429, 0.01735224947333336, 0.0], [0.6555968523025513, 0.05091030150651932, 0.028384873643517494, 0.125655397772789, 0.1054687574505806, 0.03398393467068672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502318501472473, 0.04976809769868851, 0.0, 0.0, 0.0, 0.0], [0.8829867243766785, 0.1000962033867836, 0.01691715233027935, 0.0, 0.0, 0.0], [0.8057456016540527, 0.14463560283184052, 0.03018922172486782, 0.01942945271730423, 0.0, 0.0], [0.8706232905387878, 0.03244058042764664, 0.02695159800350666, 0.04410297051072121, 0.025881517678499222, 0.0], [0.6883644461631775, 0.00968148186802864, 0.016449354588985443, 0.09871124476194382, 0.08971203118562698, 0.09708139300346375]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683124542236, 0.020731747150421143, 0.0, 0.0, 0.0, 0.0], [0.9523284435272217, 0.025933869183063507, 0.02173773944377899, 0.0, 0.0, 0.0], [0.9144353866577148, 0.017671285197138786, 0.02235853485763073, 0.045534808188676834, 0.0, 0.0], [0.9448293447494507, 0.006467591971158981, 0.006386054679751396, 0.03263082355260849, 0.009686139412224293, 0.0], [0.9347907304763794, 0.007862498052418232, 0.007788168732076883, 0.02143275924026966, 0.008491129614412785, 0.0196347888559103]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9833701848983765, 0.01662975549697876, 0.0, 0.0, 0.0, 0.0], [0.9631112813949585, 0.009229970164597034, 0.02765871398150921, 0.0, 0.0, 0.0], [0.9706628322601318, 0.004149409011006355, 0.006813114508986473, 0.01837460696697235, 0.0, 0.0], [0.987951934337616, 0.0021658889017999172, 0.0003490102826617658, 0.001583811710588634, 0.007949435152113438, 0.0], [0.945794939994812, 0.014583585783839226, 0.00036529666977003217, 0.0009569558897055686, 0.01362166740000248, 0.024677546694874763]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.012194057926535606, 0.0, 0.0, 0.0, 0.0], [0.8710366487503052, 0.0944816991686821, 0.03448163717985153, 0.0, 0.0, 0.0], [0.6309780478477478, 0.11090393364429474, 0.1923023909330368, 0.06581564992666245, 0.0, 0.0], [0.5360495448112488, 0.04618944227695465, 0.13605298101902008, 0.2645546793937683, 0.01715332642197609, 0.0], [0.8287513852119446, 0.02373281493782997, 0.02008042484521866, 0.07245299965143204, 0.0304313562810421, 0.02455105073750019]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995685577392578, 0.10043143481016159, 0.0, 0.0, 0.0, 0.0], [0.270342618227005, 0.6504339575767517, 0.07922345399856567, 0.0, 0.0, 0.0], [0.20541740953922272, 0.5892512798309326, 0.180857852101326, 0.02447350136935711, 0.0, 0.0], [0.5573872327804565, 0.17741312086582184, 0.0880676656961441, 0.09881818294525146, 0.07831382751464844, 0.0], [0.5922901034355164, 0.08700644969940186, 0.056432779878377914, 0.05685899406671524, 0.1218155100941658, 0.08559606969356537]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316376447677612, 0.068362295627594, 0.0, 0.0, 0.0, 0.0], [0.9572947025299072, 0.02624349854886532, 0.016461782157421112, 0.0, 0.0, 0.0], [0.9880544543266296, 0.004273331258445978, 0.0029545812867581844, 0.004717642907053232, 0.0, 0.0], [0.99403977394104, 0.0009413447696715593, 0.00047398178139701486, 0.00011646964412648231, 0.004428428132086992, 0.0], [0.9806035161018372, 2.5468958483543247e-05, 0.00016239396063610911, 0.0001476412871852517, 0.001344241201877594, 0.017716852948069572]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821870803833008, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.013184132054448128, 0.011163455434143543, 0.0, 0.0, 0.0], [0.9418967962265015, 0.004721763078123331, 0.0023818148765712976, 0.0509997121989727, 0.0, 0.0], [0.9905040860176086, 0.0022848148364573717, 6.19848578935489e-05, 0.0005984479794278741, 0.006550685502588749, 0.0], [0.9697661399841309, 0.0008878838270902634, 0.0002346673863939941, 0.0017040770035237074, 0.004128350410610437, 0.02327890321612358]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716230630874634, 0.0283768679946661, 0.0, 0.0, 0.0, 0.0], [0.9223619699478149, 0.028907284140586853, 0.048730771988630295, 0.0, 0.0, 0.0], [0.8426315784454346, 0.02387218549847603, 0.04748142883181572, 0.0860147550702095, 0.0, 0.0], [0.8521116375923157, 0.020744290202856064, 0.044946324080228806, 0.05765015631914139, 0.024547478184103966, 0.0], [0.8800724744796753, 0.02244853600859642, 0.01823573186993599, 0.01925482228398323, 0.015854286029934883, 0.04413414001464844]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412722587585449, 0.05872778967022896, 0.0, 0.0, 0.0, 0.0], [0.9163140654563904, 0.05759185180068016, 0.026094017550349236, 0.0, 0.0, 0.0], [0.8392423987388611, 0.05769050121307373, 0.013829062692821026, 0.08923796564340591, 0.0, 0.0], [0.8987160921096802, 0.013477860949933529, 0.0003456451231613755, 0.0032987555023282766, 0.08416163921356201, 0.0], [0.8701690435409546, 0.0027008659671992064, 0.0014349978882819414, 0.0056661684066057205, 0.08874314278364182, 0.031285740435123444]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.03432748094201088, 0.0, 0.0, 0.0, 0.0], [0.9178615212440491, 0.062257926911115646, 0.019880497828125954, 0.0, 0.0, 0.0], [0.8233146667480469, 0.06282396614551544, 0.03670436143875122, 0.07715708762407303, 0.0, 0.0], [0.8501746654510498, 0.03816923871636391, 0.031964968889951706, 0.05160145089030266, 0.028089623898267746, 0.0], [0.6572403907775879, 0.0587739571928978, 0.04336011782288551, 0.09013210982084274, 0.08146586269140244, 0.06902758777141571]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162064790725708, 0.083793506026268, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.040992818772792816, 0.013829846866428852, 0.0, 0.0, 0.0], [0.8928354978561401, 0.05368676036596298, 0.01759696751832962, 0.035880785435438156, 0.0, 0.0], [0.8337051868438721, 0.04799617826938629, 0.033513251692056656, 0.0468086414039135, 0.03797678276896477, 0.0], [0.8167194724082947, 0.06337127834558487, 0.013286269269883633, 0.020469754934310913, 0.025292271748185158, 0.06086096167564392]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525133371353149, 0.04748661443591118, 0.0, 0.0, 0.0, 0.0], [0.30198633670806885, 0.6520944833755493, 0.045919183641672134, 0.0, 0.0, 0.0], [0.2855835556983948, 0.5569521188735962, 0.14447391033172607, 0.012990497052669525, 0.0, 0.0], [0.8438040018081665, 0.03225131705403328, 0.03954288363456726, 0.06848171353340149, 0.01592012494802475, 0.0], [0.6664936542510986, 0.06095915287733078, 0.04064338654279709, 0.06804481148719788, 0.09186346083879471, 0.07199545204639435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682656526565552, 0.031734418123960495, 0.0, 0.0, 0.0, 0.0], [0.7385215759277344, 0.22856871783733368, 0.03290969505906105, 0.0, 0.0, 0.0], [0.5946669578552246, 0.23033174872398376, 0.1486765593290329, 0.02632465586066246, 0.0, 0.0], [0.6339261531829834, 0.058130085468292236, 0.09654293209314346, 0.14291933178901672, 0.06848142296075821, 0.0], [0.40375757217407227, 0.08945360779762268, 0.07635073363780975, 0.255870521068573, 0.14330360293388367, 0.031263869255781174]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020600192248821, 0.0, 0.0, 0.0, 0.0], [0.863138735294342, 0.11056642234325409, 0.026294825598597527, 0.0, 0.0, 0.0], [0.9488077759742737, 0.02861507050693035, 0.006535581778734922, 0.016041584312915802, 0.0, 0.0], [0.9672170877456665, 0.006604989990592003, 0.0004517161869443953, 0.004844421520829201, 0.020881719887256622, 0.0], [0.9354623556137085, 0.0204780176281929, 0.001170022296719253, 0.007056924514472485, 0.016318105161190033, 0.01951460912823677]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.01533269602805376, 0.0, 0.0, 0.0, 0.0], [0.9052745699882507, 0.08373622596263885, 0.010989241302013397, 0.0, 0.0, 0.0], [0.814594030380249, 0.042837489396333694, 0.10568274557590485, 0.0368858203291893, 0.0, 0.0], [0.23519699275493622, 0.012018428184092045, 0.05280094966292381, 0.6516199111938477, 0.048363760113716125, 0.0], [0.31818681955337524, 0.01863236539065838, 0.03948163613677025, 0.3755547106266022, 0.20787166059017181, 0.040272727608680725]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826739862561226, 0.0, 0.0, 0.0, 0.0], [0.8618937730789185, 0.0647917315363884, 0.07331447303295135, 0.0, 0.0, 0.0], [0.7664536833763123, 0.07330439984798431, 0.10353528708219528, 0.05670657008886337, 0.0, 0.0], [0.8128500580787659, 0.03215484321117401, 0.05900546908378601, 0.05416510999202728, 0.04182443022727966, 0.0], [0.8687862157821655, 0.02698776312172413, 0.02046988718211651, 0.01629730872809887, 0.032183703035116196, 0.035275109112262726]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264581799507141, 0.07354183495044708, 0.0, 0.0, 0.0, 0.0], [0.8403534293174744, 0.06373776495456696, 0.0959087386727333, 0.0, 0.0, 0.0], [0.7330995202064514, 0.06451123207807541, 0.10380081832408905, 0.09858846664428711, 0.0, 0.0], [0.9143611788749695, 0.008257807232439518, 0.007320408709347248, 0.01796630211174488, 0.05209442973136902, 0.0], [0.8971914052963257, 0.008555497974157333, 0.007019439246505499, 0.014860527589917183, 0.03399759903550148, 0.03837534412741661]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180346727371216, 0.08196533471345901, 0.0, 0.0, 0.0, 0.0], [0.8328660726547241, 0.12199065834283829, 0.045143257826566696, 0.0, 0.0, 0.0], [0.7994153499603271, 0.08744156360626221, 0.03605782240629196, 0.07708528637886047, 0.0, 0.0], [0.8809850215911865, 0.02074967324733734, 0.020554570481181145, 0.01712082512676716, 0.060589876025915146, 0.0], [0.7453039288520813, 0.04433402791619301, 0.022549191489815712, 0.033152736723423004, 0.03357040509581566, 0.12108971923589706]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293899595737457, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414142489433289, 0.0054081035777926445, 0.0, 0.0, 0.0], [0.96304851770401, 0.015290786512196064, 0.010345697402954102, 0.011314956471323967, 0.0, 0.0], [0.9213568568229675, 0.014132496900856495, 0.017639189958572388, 0.016567690297961235, 0.030303703621029854, 0.0], [0.9373330473899841, 0.009064311161637306, 0.007548339664936066, 0.006576436571776867, 0.011827593669295311, 0.027650361880660057]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.00489962799474597, 0.0, 0.0, 0.0, 0.0], [0.9476007223129272, 0.041407953947782516, 0.010991264134645462, 0.0, 0.0, 0.0], [0.9142175316810608, 0.023523805662989616, 0.03914501518011093, 0.02311362884938717, 0.0, 0.0], [0.9534734487533569, 0.008932976052165031, 0.015272831544280052, 0.007908296771347523, 0.01441233605146408, 0.0], [0.9427104592323303, 0.008233043365180492, 0.0046509732492268085, 0.004178094677627087, 0.0054635051637887955, 0.03476400673389435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543375372886658, 0.04566241055727005, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.019547609612345695, 0.010848305188119411, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425409629940987, 0.008068887516856194, 0.008460711687803268, 0.0, 0.0], [0.9726192951202393, 0.002697661053389311, 0.0004483141237869859, 0.0013814771082252264, 0.022853175178170204, 0.0], [0.9675466418266296, 0.009613418020308018, 0.0032030276488512754, 0.004248825367540121, 0.0074422359466552734, 0.007945875637233257]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299148201942444, 0.0, 0.0, 0.0, 0.0], [0.9382631182670593, 0.04204246401786804, 0.019694389775395393, 0.0, 0.0, 0.0], [0.8351995944976807, 0.034878626465797424, 0.051344748586416245, 0.07857709378004074, 0.0, 0.0], [0.9042678475379944, 0.010541587136685848, 0.016426727175712585, 0.02592189982533455, 0.04284190386533737, 0.0], [0.8913140296936035, 0.008912663906812668, 0.005010687280446291, 0.00817559752613306, 0.013514691032469273, 0.07307220995426178]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693915009498596, 0.13060854375362396, 0.0, 0.0, 0.0, 0.0], [0.3507999777793884, 0.6063508987426758, 0.0428491048514843, 0.0, 0.0, 0.0], [0.35475727915763855, 0.3502015769481659, 0.24722374975681305, 0.04781733825802803, 0.0, 0.0], [0.35370829701423645, 0.03527732938528061, 0.09567102789878845, 0.4497946500778198, 0.06554868817329407, 0.0], [0.41325902938842773, 0.09055528044700623, 0.05286572128534317, 0.17467984557151794, 0.17384859919548035, 0.0947914645075798]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.03702434524893761, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.019658586010336876, 0.00469872634857893, 0.0, 0.0, 0.0], [0.9775736331939697, 0.013286303728818893, 0.002559040440246463, 0.006581075489521027, 0.0, 0.0], [0.9870141744613647, 0.007388271391391754, 0.000957920856308192, 0.001831832341849804, 0.0028077582828700542, 0.0], [0.9409245848655701, 0.016633689403533936, 0.0022979099303483963, 0.005890651606023312, 0.005512924864888191, 0.02874019183218479]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9628270864486694, 0.03717285394668579, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641864001750946, 0.017134418711066246, 0.0, 0.0, 0.0], [0.9351300001144409, 0.015331589616835117, 0.014810995198786259, 0.03472748026251793, 0.0, 0.0], [0.9225173592567444, 0.010528748854994774, 0.011010152287781239, 0.019440028816461563, 0.03650377318263054, 0.0], [0.8420167565345764, 0.04357195645570755, 0.007488266099244356, 0.01496153511106968, 0.023852793499827385, 0.06810864061117172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.007361333351582289, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.003346970770508051, 0.00091368897119537, 0.0, 0.0, 0.0], [0.9869900345802307, 0.0019747859332710505, 0.0015245546819642186, 0.009510686621069908, 0.0, 0.0], [0.9933527708053589, 0.001020328258164227, 0.00034337403485551476, 0.001029114704579115, 0.004254393745213747, 0.0], [0.9749016761779785, 0.0004348019137978554, 0.000430655520176515, 0.0012364384019747376, 0.001534773618914187, 0.021461637690663338]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252486914396286, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.016509056091308594, 0.00442709494382143, 0.0, 0.0, 0.0], [0.9521436095237732, 0.02943236567080021, 0.008943174965679646, 0.009480932727456093, 0.0, 0.0], [0.9395942091941833, 0.021510910242795944, 0.010278534144163132, 0.004555221181362867, 0.024061065167188644, 0.0], [0.9205074310302734, 0.01615365780889988, 0.010818609036505222, 0.01664443127810955, 0.014566411264240742, 0.02130948379635811]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898502826690674, 0.01014977227896452, 0.0, 0.0, 0.0, 0.0], [0.9820910096168518, 0.0069075338542461395, 0.011001535691320896, 0.0, 0.0, 0.0], [0.9684997200965881, 0.0089876102283597, 0.015342569909989834, 0.007170100696384907, 0.0, 0.0], [0.9274120330810547, 0.009485269896686077, 0.02206611819565296, 0.03222890570759773, 0.008807665668427944, 0.0], [0.9006660580635071, 0.02162371575832367, 0.013808215968310833, 0.009843839332461357, 0.008521351031959057, 0.04553685709834099]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555594641715288, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460234332829714, 0.0022854835260659456, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.0040722922421991825, 0.008166342042386532, 0.0, 0.0], [0.9889963865280151, 0.0012260458897799253, 0.0007996382773853838, 0.0006774249486625195, 0.008300590328872204, 0.0], [0.9865202903747559, 0.0003942706680390984, 0.0009571767877787352, 0.0004954360192641616, 0.0009604952065274119, 0.010672261007130146]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870519310235977, 0.0, 0.0, 0.0, 0.0], [0.7489445805549622, 0.22002629935741425, 0.03102915547788143, 0.0, 0.0, 0.0], [0.2854783236980438, 0.21125619113445282, 0.47871607542037964, 0.024549338966608047, 0.0, 0.0], [0.8056642413139343, 0.02697453647851944, 0.04302811250090599, 0.06993735581636429, 0.05439591035246849, 0.0], [0.330721914768219, 0.022326510399580002, 0.016627032309770584, 0.080194391310215, 0.41574740409851074, 0.13438260555267334]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225370079278946, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.01501889992505312, 0.004924521781504154, 0.0, 0.0, 0.0], [0.9237861037254333, 0.052764732390642166, 0.006302398629486561, 0.017146700993180275, 0.0, 0.0], [0.9451842904090881, 0.03618054464459419, 0.001989212818443775, 0.0039587244391441345, 0.01268730964511633, 0.0], [0.9633325934410095, 0.018663031980395317, 0.0030418476089835167, 0.007070912979543209, 0.0050094276666641235, 0.0028820668812841177]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.987324595451355, 0.012675448320806026, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.005541946738958359, 0.004001116845756769, 0.0, 0.0, 0.0], [0.9814971685409546, 0.004653455223888159, 0.00372527539730072, 0.010124039836227894, 0.0, 0.0], [0.9744364619255066, 0.004632262047380209, 0.002379997167736292, 0.006518092937767506, 0.012033062055706978, 0.0], [0.9624499678611755, 0.0033743453677743673, 0.0013198527740314603, 0.0017274925485253334, 0.002944671083241701, 0.028183719143271446]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807673692703247, 0.019232625141739845, 0.0, 0.0, 0.0, 0.0], [0.9664247035980225, 0.0154139194637537, 0.01816137507557869, 0.0, 0.0, 0.0], [0.9632683396339417, 0.004538131412118673, 0.0029253889806568623, 0.029268164187669754, 0.0, 0.0], [0.9562349915504456, 0.0012223643716424704, 0.0005304075893945992, 0.008671474643051624, 0.033340781927108765, 0.0], [0.9657101035118103, 0.0009808274917304516, 0.0016686212038621306, 0.0026348272804170847, 0.005866338964551687, 0.02313929796218872]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639714956283569, 0.036028504371643066, 0.0, 0.0, 0.0, 0.0], [0.9562800526618958, 0.033733122050762177, 0.009986838325858116, 0.0, 0.0, 0.0], [0.853999674320221, 0.08073031902313232, 0.03334450349211693, 0.031925544142723083, 0.0, 0.0], [0.9547489881515503, 0.0096050426363945, 0.00414617033675313, 0.002013325458392501, 0.02948645129799843, 0.0], [0.933113694190979, 0.028699707239866257, 0.005477478262037039, 0.006368071772158146, 0.012613070197403431, 0.013728084973990917]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.060700662434101105, 0.0, 0.0, 0.0, 0.0], [0.9298389554023743, 0.061895497143268585, 0.008265494368970394, 0.0, 0.0, 0.0], [0.8471820950508118, 0.09035064280033112, 0.017636114731431007, 0.04483110085129738, 0.0, 0.0], [0.8857702016830444, 0.03918180242180824, 0.007867713458836079, 0.022765880450606346, 0.0444144681096077, 0.0], [0.8563281893730164, 0.10088981688022614, 0.00653143459931016, 0.008485895581543446, 0.0073684388771653175, 0.020396238192915916]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353262543678284, 0.16467373073101044, 0.0, 0.0, 0.0, 0.0], [0.6160860061645508, 0.3137648403644562, 0.07014918327331543, 0.0, 0.0, 0.0], [0.34316354990005493, 0.27584975957870483, 0.11966027319431305, 0.261326402425766, 0.0, 0.0], [0.5908167958259583, 0.05029088631272316, 0.04166605323553085, 0.2199493646621704, 0.09727690368890762, 0.0], [0.8481416702270508, 0.0631808340549469, 0.014733636751770973, 0.05526723712682724, 0.009014973416924477, 0.009661651216447353]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627320766448975, 0.03726791962981224, 0.0, 0.0, 0.0, 0.0], [0.7757521867752075, 0.17996282875537872, 0.044284969568252563, 0.0, 0.0, 0.0], [0.6317057609558105, 0.24380743503570557, 0.10925643891096115, 0.015230290591716766, 0.0, 0.0], [0.9539909958839417, 0.01818232797086239, 0.011601817794144154, 0.01229910645633936, 0.003925777971744537, 0.0], [0.40357086062431335, 0.14237552881240845, 0.056611865758895874, 0.19757317006587982, 0.09299169480800629, 0.10687682777643204]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.01973811723291874, 0.0, 0.0, 0.0, 0.0], [0.9873908162117004, 0.007800452411174774, 0.004808676429092884, 0.0, 0.0, 0.0], [0.9283919334411621, 0.00830123946070671, 0.01330562774091959, 0.05000118911266327, 0.0, 0.0], [0.8981053829193115, 0.015591327100992203, 0.01017757598310709, 0.03998705744743347, 0.03613865002989769, 0.0], [0.975350022315979, 0.0003543295315466821, 0.0005866009742021561, 0.0011877480428665876, 0.0010750859510153532, 0.021446382626891136]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.0704670250415802, 0.0, 0.0, 0.0, 0.0], [0.9361505508422852, 0.04116692394018173, 0.022682547569274902, 0.0, 0.0, 0.0], [0.8486821055412292, 0.05802806839346886, 0.024856165051460266, 0.0684337243437767, 0.0, 0.0], [0.8661178946495056, 0.02232472598552704, 0.010369138792157173, 0.026001976802945137, 0.07518625259399414, 0.0], [0.8074422478675842, 0.04438253492116928, 0.01849709264934063, 0.03357789292931557, 0.0185612291097641, 0.07753899693489075]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680536389350891, 0.031946372240781784, 0.0, 0.0, 0.0, 0.0], [0.9693689942359924, 0.025684954598546028, 0.004946068394929171, 0.0, 0.0, 0.0], [0.9620568156242371, 0.02255246415734291, 0.005471329670399427, 0.00991946179419756, 0.0, 0.0], [0.9727528095245361, 0.010137127712368965, 0.0007573263137601316, 0.0028828911017626524, 0.013469814322888851, 0.0], [0.9624637365341187, 0.00311090424656868, 0.00100075569935143, 0.0019475899171084166, 0.008266208693385124, 0.023210842162370682]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542505502700806, 0.14574943482875824, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116342179477215, 0.013286862522363663, 0.0, 0.0, 0.0], [0.9257622957229614, 0.03257261589169502, 0.014612065628170967, 0.02705308608710766, 0.0, 0.0], [0.7923429012298584, 0.027305010706186295, 0.01880667358636856, 0.1385413110256195, 0.02300402708351612, 0.0], [0.6152051091194153, 0.026655299589037895, 0.029352962970733643, 0.0559089221060276, 0.11611286550760269, 0.15676498413085938]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534558057785034, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.0075094737112522125, 0.004245333839207888, 0.0, 0.0, 0.0], [0.9584206342697144, 0.010963579639792442, 0.010456085205078125, 0.020159730687737465, 0.0, 0.0], [0.9604810476303101, 0.007182636763900518, 0.003072344930842519, 0.0068989223800599575, 0.022365106269717216, 0.0], [0.966888964176178, 0.0032812876161187887, 0.005500528495758772, 0.004234079271554947, 0.005038034170866013, 0.015057181939482689]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498193860054016, 0.050180625170469284, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430046409368515, 0.005433559417724609, 0.0, 0.0, 0.0], [0.8618695139884949, 0.03609364852309227, 0.07555560022592545, 0.026481211185455322, 0.0, 0.0], [0.5449836850166321, 0.015411168336868286, 0.02351653389632702, 0.25743618607521057, 0.1586524099111557, 0.0], [0.9571872353553772, 0.0030803889967501163, 0.001444686553440988, 0.006861576810479164, 0.014818795025348663, 0.01660728268325329]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156561374664307, 0.3843438923358917, 0.0, 0.0, 0.0, 0.0], [0.36760637164115906, 0.4281637370586395, 0.20422989130020142, 0.0, 0.0, 0.0], [0.16471558809280396, 0.4136791527271271, 0.25092360377311707, 0.1706816852092743, 0.0, 0.0], [0.4184460937976837, 0.15247608721256256, 0.10305383056402206, 0.11071506887674332, 0.21530893445014954, 0.0], [0.19686944782733917, 0.2014620304107666, 0.12827250361442566, 0.0920325294137001, 0.09167566150426865, 0.28968778252601624]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027365446090698, 0.09726346284151077, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004308730363846, 0.012332303449511528, 0.0, 0.0, 0.0], [0.8504457473754883, 0.05690574273467064, 0.03206087276339531, 0.06058763712644577, 0.0, 0.0], [0.766120970249176, 0.035303935408592224, 0.03433044254779816, 0.09675208479166031, 0.06749249249696732, 0.0], [0.8650376796722412, 0.020085245370864868, 0.0114980423822999, 0.018558325245976448, 0.018430287018418312, 0.06639042496681213]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.03469175100326538, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176092110574245, 0.004191520158201456, 0.0, 0.0, 0.0], [0.9275255799293518, 0.0473722405731678, 0.011528268456459045, 0.013573979958891869, 0.0, 0.0], [0.9293115139007568, 0.025833338499069214, 0.007227125111967325, 0.01430062297731638, 0.023327331990003586, 0.0], [0.8895061612129211, 0.046896226704120636, 0.004717112518846989, 0.006286595948040485, 0.006090151146054268, 0.046503737568855286]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619737207889557, 0.0, 0.0, 0.0, 0.0], [0.8221706748008728, 0.063044972717762, 0.11478440463542938, 0.0, 0.0, 0.0], [0.5047378540039062, 0.15375757217407227, 0.22770363092422485, 0.11380091309547424, 0.0, 0.0], [0.40820738673210144, 0.09066358208656311, 0.11696857213973999, 0.24553203582763672, 0.13862840831279755, 0.0], [0.7291041016578674, 0.06638885289430618, 0.023112762719392776, 0.03110307641327381, 0.05714317411184311, 0.09314802289009094]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247532486915588, 0.07524676620960236, 0.0, 0.0, 0.0, 0.0], [0.8957375288009644, 0.06989562511444092, 0.03436676785349846, 0.0, 0.0, 0.0], [0.7924938201904297, 0.09601156413555145, 0.055091120302677155, 0.056403499096632004, 0.0, 0.0], [0.7891507148742676, 0.07880303263664246, 0.03840154409408569, 0.05396977812051773, 0.039674971252679825, 0.0], [0.780785858631134, 0.07993540912866592, 0.04253171756863594, 0.03234210982918739, 0.017816951498389244, 0.04658801481127739]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191135033965111, 0.0, 0.0, 0.0, 0.0], [0.8636949062347412, 0.047562092542648315, 0.08874304592609406, 0.0, 0.0, 0.0], [0.9341371059417725, 0.022224130108952522, 0.022624509409070015, 0.021014362573623657, 0.0, 0.0], [0.9588144421577454, 0.008020910434424877, 0.004490078892558813, 0.00586229981854558, 0.022812405601143837, 0.0], [0.938591718673706, 0.02122773416340351, 0.0048724752850830555, 0.010940182954072952, 0.009524590335786343, 0.01484343409538269]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.023626603186130524, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189403425902128, 0.006330370437353849, 0.0, 0.0, 0.0], [0.9477092027664185, 0.017985165119171143, 0.0101566007360816, 0.024149015545845032, 0.0, 0.0], [0.967192530632019, 0.006552820093929768, 0.003322787582874298, 0.005563332699239254, 0.017368430271744728, 0.0], [0.9584562182426453, 0.007502953987568617, 0.0051363264210522175, 0.008071641437709332, 0.005997130647301674, 0.014835829846560955]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.884070873260498, 0.11592914164066315, 0.0, 0.0, 0.0, 0.0], [0.993125319480896, 0.0050708153285086155, 0.0018038052367046475, 0.0, 0.0, 0.0], [0.9534158110618591, 0.023829087615013123, 0.007748983334749937, 0.015006095170974731, 0.0, 0.0], [0.9151288270950317, 0.010873124934732914, 0.013190999627113342, 0.011050461791455746, 0.049756716936826706, 0.0], [0.8769674301147461, 0.03385210409760475, 0.008486478589475155, 0.009969156235456467, 0.03468579426407814, 0.036039117723703384]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709519514814019, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.52503949822858e-05, 0.37378302216529846, 0.6261518001556396, 0.0, 0.0, 0.0], [4.606039874488488e-05, 0.21050886809825897, 0.411596417427063, 0.377848744392395, 0.0, 0.0], [4.7531026211800054e-05, 0.11616962403059006, 0.23264268040657043, 0.3985332250595093, 0.2526068687438965, 0.0], [1.2476449455789407e-06, 0.1481970250606537, 0.15813151001930237, 0.30074411630630493, 0.11939028650522232, 0.273535817861557]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.02844420075416565, 0.0, 0.0, 0.0, 0.0], [0.9529063701629639, 0.03233078494668007, 0.014762787148356438, 0.0, 0.0, 0.0], [0.9343128204345703, 0.023512953892350197, 0.020498033612966537, 0.021676233038306236, 0.0, 0.0], [0.9529678225517273, 0.00855142343789339, 0.004359327722340822, 0.008064564317464828, 0.026056958362460136, 0.0], [0.9653593897819519, 0.008487634360790253, 0.003499275306239724, 0.002721574855968356, 0.0032828773837536573, 0.016649343073368073]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.13692186772823334, 0.0, 0.0, 0.0, 0.0], [0.7696157097816467, 0.08513346314430237, 0.14525090157985687, 0.0, 0.0, 0.0], [0.7133336067199707, 0.1017090305685997, 0.11931272596120834, 0.06564465165138245, 0.0, 0.0], [0.7186216711997986, 0.05444302782416344, 0.013868178240954876, 0.0780804380774498, 0.13498668372631073, 0.0], [0.7990152835845947, 0.058055855333805084, 0.009447006508708, 0.017770448699593544, 0.021138517186045647, 0.09457287937402725]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.04810114949941635, 0.0, 0.0, 0.0, 0.0], [0.8580654263496399, 0.029445774853229523, 0.11248882114887238, 0.0, 0.0, 0.0], [0.6577739119529724, 0.08513441681861877, 0.12613077461719513, 0.1309608817100525, 0.0, 0.0], [0.8087368607521057, 0.03230159357190132, 0.018418151885271072, 0.06856140494346619, 0.07198190689086914, 0.0], [0.668330192565918, 0.13281351327896118, 0.021880602464079857, 0.02787742204964161, 0.049234092235565186, 0.09986425936222076]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-af834f93a11e44c19c8fb48c463825ac\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12} is a template marker that is replaced by actual params.\n",
              "        const config = {};\n",
              "\n",
              "        const MIN_X = 0;\n",
              "        const MIN_Y = 0;\n",
              "        const DIV_WIDTH = 970;\n",
              "        const THUMBNAIL_PADDING = 5;\n",
              "        const DETAIL_WIDTH = 300;\n",
              "        const DETAIL_ATTENTION_WIDTH = 140;\n",
              "        const DETAIL_BOX_WIDTH = 80;\n",
              "        const DETAIL_BOX_HEIGHT = 18;\n",
              "        const DETAIL_PADDING = 15;\n",
              "        const ATTN_PADDING = 0;\n",
              "        const DETAIL_HEADING_HEIGHT = 25;\n",
              "        const HEADING_TEXT_SIZE = 15;\n",
              "        const HEADING_PADDING = 5;\n",
              "        const TEXT_SIZE = 13;\n",
              "        const TEXT_PADDING = 5;\n",
              "        const LAYER_COLORS = d3.schemeCategory10;\n",
              "        const PALETTE = {\n",
              "            'light': {\n",
              "                'text': 'black',\n",
              "                'background': 'white',\n",
              "                'highlight': '#F5F5F5'\n",
              "            },\n",
              "            'dark': {\n",
              "                'text': '#ccc',\n",
              "                'background': 'black',\n",
              "                'highlight': '#222'\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function render() {\n",
              "\n",
              "            // Set global state variables\n",
              "\n",
              "            var attData = config.attention[config.filter];\n",
              "            config.leftText = attData.left_text;\n",
              "            config.rightText = attData.right_text;\n",
              "            config.attn = attData.attn;\n",
              "            config.numLayers = config.attn.length;\n",
              "            config.numHeads = config.attn[0].length;\n",
              "            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
              "            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n",
              "            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n",
              "            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n",
              "\n",
              "            const vis = $(`#${config.rootDivId} #vis`)\n",
              "            vis.empty();\n",
              "            vis.attr(\"height\", config.divHeight);\n",
              "            config.svg = d3.select(`#${config.rootDivId} #vis`)\n",
              "                .append('svg')\n",
              "                .attr(\"width\", DIV_WIDTH)\n",
              "                .attr(\"height\", config.divHeight)\n",
              "                .attr(\"fill\", getBackgroundColor());\n",
              "\n",
              "            renderAxisLabels();\n",
              "\n",
              "            var i;\n",
              "            var j;\n",
              "            for (i = 0; i < config.numLayers; i++) {\n",
              "                for (j = 0; j < config.numHeads; j++) {\n",
              "                    renderThumbnail(i, j);\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function renderAxisLabels() {\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            const tableWidth = config.thumbnailWidth * config.heads.length;\n",
              "            config.svg.append(\"text\")\n",
              "                .text(\"Heads\")\n",
              "                .attr(\"fill\", \"black\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
              "                .attr(\"x\", axisSize + tableWidth / 2)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", 0)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "            for (let i = 0; i < config.numHeads; i++) {\n",
              "                config.svg.append(\"text\")\n",
              "                    .text(config.heads[i])\n",
              "                    .attr(\"fill\", \"black\")\n",
              "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n",
              "                    .attr(\"text-anchor\", \"middle\")\n",
              "                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n",
              "                    .attr(\"dy\", TEXT_SIZE);\n",
              "            }\n",
              "            let x = 0;\n",
              "            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n",
              "            console.log(\"x\", x, y)\n",
              "            config.svg.append(\"text\")\n",
              "                .text(\"Layers\")\n",
              "                .attr(\"fill\", \"black\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n",
              "                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "            for (let i = 0; i < config.numLayers; i++) {\n",
              "                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n",
              "                y = axisSize + (i + .5) * config.thumbnailHeight;\n",
              "                config.svg.append(\"text\")\n",
              "                    .text(config.layers[i])\n",
              "                    .attr(\"fill\", \"black\")\n",
              "                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                    .attr(\"x\", x)\n",
              "                    .attr(\"text-anchor\", \"end\")\n",
              "                    .attr(\"y\", y)\n",
              "                    .attr(\"dy\", TEXT_SIZE / 2);\n",
              "            }\n",
              "        }\n",
              "\n",
              "\n",
              "        function renderThumbnail(layerIndex, headIndex) {\n",
              "            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n",
              "            const x = headIndex * config.thumbnailWidth + axisSize;\n",
              "            const y = layerIndex * config.thumbnailHeight + axisSize;\n",
              "            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n",
              "        }\n",
              "\n",
              "        function renderDetail(att, layerIndex, headIndex) {\n",
              "            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n",
              "            var xOffset = .8 * config.thumbnailWidth;\n",
              "            var maxX = DIV_WIDTH;\n",
              "            var maxY = config.divHeight - 3;\n",
              "            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n",
              "            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n",
              "            if (x < MIN_X) {\n",
              "                x = MIN_X;\n",
              "            } else if (x + DETAIL_WIDTH > maxX) {\n",
              "                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n",
              "            }\n",
              "            var posLeftText = x;\n",
              "            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n",
              "            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n",
              "            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n",
              "            var yOffset = 20;\n",
              "            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n",
              "            if (y < MIN_Y) {\n",
              "                y = MIN_Y;\n",
              "            } else if (y + config.detailHeight > maxY) {\n",
              "                y = maxY - config.detailHeight;\n",
              "            }\n",
              "            renderDetailFrame(x, y, layerIndex);\n",
              "            y = y + DETAIL_PADDING;\n",
              "            renderDetailHeading(x, y, layerIndex, headIndex);\n",
              "            y = y + DETAIL_HEADING_HEIGHT;\n",
              "            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n",
              "            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n",
              "            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n",
              "        }\n",
              "\n",
              "        function renderDetailHeading(x, y, layerIndex, headIndex) {\n",
              "            var fillColor = getTextColor();\n",
              "            config.svg.append(\"text\")\n",
              "                .classed(\"detail\", true)\n",
              "                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n",
              "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                .attr(\"font-weight\", \"bold\")\n",
              "                .style(\"cursor\", \"default\")\n",
              "                .style(\"-webkit-user-select\", \"none\")\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .attr(\"x\", x + DETAIL_WIDTH / 2)\n",
              "                .attr(\"text-anchor\", \"middle\")\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_WIDTH)\n",
              "                .attr(\"dy\", HEADING_TEXT_SIZE);\n",
              "        }\n",
              "\n",
              "        function renderDetailText(text, id, x, y, layerIndex) {\n",
              "            var tokenContainer = config.svg.append(\"svg:g\")\n",
              "                .classed(\"detail\", true)\n",
              "                .selectAll(\"g\")\n",
              "                .data(text)\n",
              "                .enter()\n",
              "                .append(\"g\");\n",
              "\n",
              "            var fillColor = getTextColor();\n",
              "\n",
              "            tokenContainer.append(\"rect\")\n",
              "                .classed(\"highlight\", true)\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .style(\"opacity\", 0.0)\n",
              "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", function (d, i) {\n",
              "                    return y + i * DETAIL_BOX_HEIGHT;\n",
              "                });\n",
              "\n",
              "            var textContainer = tokenContainer.append(\"text\")\n",
              "                .classed(\"token\", true)\n",
              "                .text(function (d) {\n",
              "                    return d;\n",
              "                })\n",
              "                .attr(\"font-size\", TEXT_SIZE + \"px\")\n",
              "                .style(\"cursor\", \"default\")\n",
              "                .style(\"-webkit-user-select\", \"none\")\n",
              "                .attr(\"fill\", fillColor)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", function (d, i) {\n",
              "                    return i * DETAIL_BOX_HEIGHT + y;\n",
              "                })\n",
              "                .attr(\"height\", DETAIL_BOX_HEIGHT)\n",
              "                .attr(\"width\", DETAIL_BOX_WIDTH)\n",
              "                .attr(\"dy\", TEXT_SIZE);\n",
              "\n",
              "            if (id == \"leftText\") {\n",
              "                textContainer.style(\"text-anchor\", \"end\")\n",
              "                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n",
              "                tokenContainer.on(\"mouseover\", function (d, index) {\n",
              "                    highlightSelection(index);\n",
              "                });\n",
              "                tokenContainer.on(\"mouseleave\", function () {\n",
              "                    unhighlightSelection();\n",
              "                });\n",
              "            }\n",
              "        }\n",
              "\n",
              "        function highlightSelection(index) {\n",
              "            config.svg.select(\"#leftText\")\n",
              "                .selectAll(\".highlight\")\n",
              "                .style(\"opacity\", function (d, i) {\n",
              "                    return i == index ? 1.0 : 0.0;\n",
              "                });\n",
              "            config.svg.selectAll(\".attn-line-group\")\n",
              "                .style(\"opacity\", function (d, i) {\n",
              "                    return i == index ? 1.0 : 0.0;\n",
              "                });\n",
              "        }\n",
              "\n",
              "        function unhighlightSelection() {\n",
              "            config.svg.select(\"#leftText\")\n",
              "                .selectAll(\".highlight\")\n",
              "                .style(\"opacity\", 0.0);\n",
              "            config.svg.selectAll(\".attn-line-group\")\n",
              "                .style(\"opacity\", 1);\n",
              "        }\n",
              "\n",
              "        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n",
              "\n",
              "            var attnContainer = config.svg.append(\"svg:g\");\n",
              "\n",
              "            var attnBackground = attnContainer.append(\"rect\")\n",
              "                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n",
              "                .classed(\"attn_background\", true)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.thumbnailHeight)\n",
              "                .attr(\"width\", config.thumbnailWidth)\n",
              "                .attr(\"stroke-width\", 2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", 0)\n",
              "                .attr(\"fill\", getBackgroundColor());\n",
              "            var x1 = x + THUMBNAIL_PADDING;\n",
              "            var x2 = x1 + config.thumbnailWidth - 14;\n",
              "            var y1 = y + THUMBNAIL_PADDING;\n",
              "\n",
              "            attnContainer.selectAll(\"g\")\n",
              "                .data(att)\n",
              "                .enter()\n",
              "                .append(\"g\") // Add group for each source token\n",
              "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
              "                    return i;\n",
              "                })\n",
              "                .selectAll(\"line\")\n",
              "                .data(function (d) { // Loop over all target tokens\n",
              "                    return d;\n",
              "                })\n",
              "                .enter() // When entering\n",
              "                .append(\"line\")\n",
              "                .attr(\"x1\", x1)\n",
              "                .attr(\"y1\", function (d) {\n",
              "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
              "                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n",
              "                })\n",
              "                .attr(\"x2\", x2)\n",
              "                .attr(\"y2\", function (d, targetIndex) {\n",
              "                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n",
              "                })\n",
              "                .attr(\"stroke-width\", 2.2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", function (d) {\n",
              "                    return d;\n",
              "                });\n",
              "\n",
              "            var clickRegion = attnContainer.append(\"rect\")\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.thumbnailHeight)\n",
              "                .attr(\"width\", config.thumbnailWidth)\n",
              "                .style(\"opacity\", 0);\n",
              "\n",
              "            clickRegion.on(\"click\", function (d, index) {\n",
              "                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n",
              "                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n",
              "                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n",
              "\n",
              "                config.svg.selectAll(\".detail\").remove();\n",
              "                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n",
              "                    renderDetail(att, layerIndex, headIndex);\n",
              "                    config.detail_layer = layerIndex;\n",
              "                    config.detail_head = headIndex;\n",
              "                    attnBackground.attr(\"fill\", getHighlightColor());\n",
              "                    attnBackground.attr(\"stroke-opacity\", .8);\n",
              "                } else {\n",
              "                    config.detail_layer = null;\n",
              "                    config.detail_head = null;\n",
              "                    attnBackground.attr(\"fill\", getBackgroundColor());\n",
              "                    attnBackground.attr(\"stroke-opacity\", 0);\n",
              "                }\n",
              "            });\n",
              "\n",
              "            clickRegion.on(\"mouseover\", function (d) {\n",
              "                d3.select(this).style(\"cursor\", \"pointer\");\n",
              "            });\n",
              "        }\n",
              "\n",
              "        function renderDetailFrame(x, y, layerIndex) {\n",
              "            var detailFrame = config.svg.append(\"rect\")\n",
              "                .classed(\"detail\", true)\n",
              "                .attr(\"x\", x)\n",
              "                .attr(\"y\", y)\n",
              "                .attr(\"height\", config.detailHeight)\n",
              "                .attr(\"width\", DETAIL_WIDTH)\n",
              "                .style(\"opacity\", 1)\n",
              "                .attr(\"stroke-width\", 1.5)\n",
              "                .attr(\"stroke-opacity\", 0.7)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex));\n",
              "        }\n",
              "\n",
              "        function renderDetailAttn(x, y, att, layerIndex) {\n",
              "            var attnContainer = config.svg.append(\"svg:g\")\n",
              "                .classed(\"detail\", true)\n",
              "                .attr(\"pointer-events\", \"none\");\n",
              "            attnContainer.selectAll(\"g\")\n",
              "                .data(att)\n",
              "                .enter()\n",
              "                .append(\"g\") // Add group for each source token\n",
              "                .classed('attn-line-group', true)\n",
              "                .attr(\"source-index\", function (d, i) { // Save index of source token\n",
              "                    return i;\n",
              "                })\n",
              "                .selectAll(\"line\")\n",
              "                .data(function (d) { // Loop over all target tokens\n",
              "                    return d;\n",
              "                })\n",
              "                .enter()\n",
              "                .append(\"line\")\n",
              "                .attr(\"x1\", x + ATTN_PADDING)\n",
              "                .attr(\"y1\", function (d) {\n",
              "                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n",
              "                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n",
              "                })\n",
              "                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n",
              "                .attr(\"y2\", function (d, targetIndex) {\n",
              "                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n",
              "                })\n",
              "                .attr(\"stroke-width\", 2.2)\n",
              "                .attr(\"stroke\", getLayerColor(layerIndex))\n",
              "                .attr(\"stroke-opacity\", function (d) {\n",
              "                    return d;\n",
              "                });\n",
              "        }\n",
              "\n",
              "        function getLayerColor(layer) {\n",
              "          return LAYER_COLORS[config.layers[layer] % 10];\n",
              "        }\n",
              "\n",
              "        function getTextColor() {\n",
              "            return PALETTE[config.mode]['text']\n",
              "        }\n",
              "\n",
              "        function getBackgroundColor() {\n",
              "           return PALETTE[config.mode]['background']\n",
              "        }\n",
              "\n",
              "        function getHighlightColor() {\n",
              "           return PALETTE[config.mode]['highlight']\n",
              "        }\n",
              "\n",
              "        function initialize() {\n",
              "            config.attention = params['attention'];\n",
              "            config.filter = params['default_filter'];\n",
              "            config.mode = params['display_mode'];\n",
              "            config.layers = params['include_layers']\n",
              "            config.heads = params['include_heads']\n",
              "            config.totalHeads = params['total_heads']\n",
              "            config.rootDivId = params['root_div_id'];\n",
              "            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n",
              "                config.filter = e.currentTarget.value;\n",
              "                render();\n",
              "            });\n",
              "        }\n",
              "\n",
              "        initialize();\n",
              "        render();\n",
              "\n",
              "    });"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
        "\n",
        "from bertviz import model_view\n",
        "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
        "\n",
        "model_name = 'openai-community/gpt2'\n",
        "input_text = \"No, I am your father\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
        "outputs = model(inputs)  # Run model\n",
        "attention = outputs[-1]  # Retrieve attention from model outputs\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
        "model_view(attention, tokens)  # Display model view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAh2n4kB_-j1"
      },
      "source": [
        "## Positional encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFq78-kjbrWp"
      },
      "source": [
        "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
        "\n",
        "Consider the following two sentences to see why this is important:\n",
        "\n",
        "``The man ate the sandwich.``\n",
        "\n",
        "``The sandwich ate the man.``\n",
        "\n",
        "Clearly, these are two vastly different situations even though they have the same words. The Transformer can\n",
        "\n",
        "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nswKwgBn_-j1"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/positional_encoding.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
        "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4fIg5Pl_-j2"
      },
      "source": [
        "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal.\n",
        "\n",
        "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lHA40AM7_-j2"
      },
      "outputs": [],
      "source": [
        "vocab_size = 65\n",
        "n_embd = 64\n",
        "\n",
        "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "position_embedding_table = nn.Embedding(block_size, n_embd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExbFwd4P_-j2"
      },
      "source": [
        "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hrsomdny_-j2"
      },
      "source": [
        "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rJ0kQ58_-j2"
      },
      "source": [
        "Let's look at token embedding alone:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "scrolled": false,
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgdwH1-b_-j2",
        "outputId": "c4d105d7-783d-4e86-d277-4049a802522a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.7221, -0.9629, -2.0578,  1.9740,  0.7434,  1.1139,  0.6926,  0.0296,\n",
            "         0.6405, -1.6464,  0.4935,  0.7485,  0.9238, -0.4940,  0.4814, -0.3859,\n",
            "        -0.3094,  1.1066, -0.2891,  0.1891,  2.0440, -0.7945, -0.4331,  0.3007,\n",
            "         1.4317,  0.2881, -0.4343,  0.4280,  1.2469,  1.4047, -0.3404, -2.2190,\n",
            "         0.4893,  0.0398, -0.2717, -2.2400, -0.0029, -1.4251,  0.7330,  0.3551,\n",
            "         0.1472, -1.1895, -0.8407,  0.3134, -0.6709, -0.8176,  0.6929, -0.6374,\n",
            "         0.3174,  0.4837, -0.0073, -1.5924,  1.8606, -1.2910, -0.1594,  0.3111,\n",
            "        -0.1536, -0.3414, -0.0170, -0.1633,  0.2794,  0.6755,  0.7066, -1.6665],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
        "x = token_embedding_table(x)\n",
        "print(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUGjhSp0_-j2"
      },
      "source": [
        "And token + positional embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO0vYISq_-j3",
        "outputId": "b1967b2b-c7aa-4b01-d6b0-f41600e65d73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.4326, -1.6287, -0.8684,  3.0704,  0.3646,  1.9826,  0.7582, -0.1918,\n",
            "         1.0491, -2.2562, -0.4931, -0.7808,  1.7206, -1.0297,  2.0798, -1.3427,\n",
            "        -0.7896, -0.1746,  0.0926,  0.0543,  2.3831, -0.6208,  0.3902,  0.1097,\n",
            "         1.0455, -1.4557,  0.3402,  2.6717,  1.8380,  1.2628, -0.4831, -4.6023,\n",
            "         0.6959,  1.0347,  0.5903, -0.7541,  0.4682, -0.3895,  2.1526,  0.6272,\n",
            "        -0.8558, -0.8434,  0.1311, -1.0272, -2.0580,  0.0584,  0.3442, -0.3464,\n",
            "        -0.3444,  2.3134, -1.1142, -1.4629,  3.3503, -2.0594,  1.4105,  0.4558,\n",
            "        -1.3366,  1.9283,  1.5187,  0.3906,  1.1448, -0.8422,  2.2692, -0.7949],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
        "x= position_embedding_table(x) + token_embedding_table(x)\n",
        "print(x[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyJVBgZN_-j3"
      },
      "source": [
        "You can see a clear offset between these two embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CYr4SXB_-j3"
      },
      "source": [
        "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF1HzH9xNJ7S"
      },
      "source": [
        "## Output layers\n",
        "\n",
        "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
        "\n",
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/transformer-decoder-intro.png?raw=1\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
        "\n",
        "Using a final Linear layer and a Softmax Layer.\n",
        "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
        "\n",
        "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide – each cell corresponds to the score of a unique word.\n",
        "\n",
        "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NHj4_if_-j3"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/transformer_decoder_output_softmax.png?raw=1\" alt=\"Drawing\" style=\"width: 450px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS6r-z8dN_RV"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK8q67P03yr4"
      },
      "source": [
        "## Training\n",
        "\n",
        "How does an LLM improve over time?\n",
        "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths.\n",
        "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths.\n",
        "For example, when translating the sentence: “je suis étudiant” into “i am a student” as can be seen in the example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IldftsPo_-j4"
      },
      "source": [
        "<img src=\"https://github.com/ellenketter/ai-science-training-series-ek/blob/main/05_llm_part2/images/output_target_probability_distributions.png?raw=1\" alt=\"Drawing\" style=\"width: 500px;\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWmrDdT3_-j4"
      },
      "source": [
        "Image credit: https://jalammar.github.io/illustrated-transformer/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dT-HjN-v_-j4"
      },
      "source": [
        "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
        "\n",
        "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
        "\n",
        "where p(x) represents the true distribution and q(x) represents the predicted distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNUKpekL_-j4",
        "outputId": "e599b629-a7bc-4150-a66c-81f7019a350c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9119)\n"
          ]
        }
      ],
      "source": [
        "from torch.nn import functional as F\n",
        "logits = torch.tensor([0.5, 0.1, 0.3])\n",
        "targets = torch.tensor([1.0, 0.0, 0.0])\n",
        "loss = F.cross_entropy(logits, targets)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAZ8YncJ_-j5"
      },
      "source": [
        "Another important metric commonly used in LLMs is **perplexity**.\n",
        "\n",
        "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtMIugBs_-j5"
      },
      "source": [
        "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
        "\n",
        "$\\text{perplexity} = exp(\\text{CE})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHAgH1X9_-j5",
        "outputId": "0c6e00b8-9d9f-4f8e-e87a-21bca5589d89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4891)\n"
          ]
        }
      ],
      "source": [
        "perplexity = torch.exp(loss)\n",
        "print(perplexity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szw2au1u_-j5"
      },
      "source": [
        "In this example, we are using cross entropy loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDDMI-rH_-j5"
      },
      "source": [
        "## Let's train a mini-LLM from scratch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhnCH2DE_-j5"
      },
      "source": [
        "### Set up hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "eXWaOBHP_-j5"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "batch_size = 16 # how many independent sequences will we process in parallel?\n",
        "block_size = 32 # what is the maximum context length for predictions?\n",
        "max_iters = 5000\n",
        "eval_interval = 10\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4\n",
        "dropout = 0.0\n",
        "# ------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U4pBZTC_-j6"
      },
      "source": [
        "### Load in data and create train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqnnE0fX_-j6"
      },
      "source": [
        "We're going to be using the tiny Shakespeare dataset.\n",
        "Data is tokenized according to a simple character based tokenizer.\n",
        "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0m0e4iXp_-j6"
      },
      "outputs": [],
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "# here are all the unique characters that occur in this text\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "# create a mapping from characters to integers\n",
        "stoi = { ch:i for i,ch in enumerate(chars) }\n",
        "itos = { i:ch for i,ch in enumerate(chars) }\n",
        "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "# Train and test splits\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "# data loading\n",
        "def get_batch(split):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djuOvFm2_-j6"
      },
      "source": [
        "### Set up the components of the Decoder block:\n",
        "* MultiHeadAttention\n",
        "* FeedForward Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "4Q89thBF_-j6"
      },
      "outputs": [],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,C) 16,32,16\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        # compute attention scores (\"affinities\")\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # perform the weighted aggregation of the values\n",
        "        v = self.value(x) # (B,T,C)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJPjIG84_-j7"
      },
      "source": [
        "### Combine components into the Decoder block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-oftSM2l_-j7"
      },
      "outputs": [],
      "source": [
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))    # Communication\n",
        "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Urkw4I0C_-j7"
      },
      "source": [
        "### Set up the full Transformer model\n",
        "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cSGuayLn_-j8"
      },
      "outputs": [],
      "source": [
        "# super simple language model\n",
        "class LanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # each token directly reads off the logits for the next token from a lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aUniEh0_-j8"
      },
      "source": [
        "We will be training a larger LLM on distributed resources in session 6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcnCOGUD_-j8"
      },
      "source": [
        "## Homework\n",
        "\n",
        "1. In this notebook, we learned the various components of an LLM.\n",
        "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
        "      \n",
        "    Hint: this function might be useful for you:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6_MZkyOx_-j8"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
        "\n",
        "def load_dataset(train_path,test_path,tokenizer):\n",
        "    train_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=train_path,\n",
        "          block_size=128)\n",
        "    test_dataset = TextDataset(\n",
        "          tokenizer=tokenizer,\n",
        "          file_path=test_path,\n",
        "          block_size=128)\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    return train_dataset,test_dataset,data_collator"
      ],
      "metadata": {
        "id": "vhPU9k2jnFmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
        "\n",
        "train_dataset,test_dataset,data_collator = load_dataset('train_input.txt','test_input.txt', tokenizer)\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./\", #The output directory\n",
        "    # overwrite_output_dir=True, #overwrite the content of the output directory\n",
        "    num_train_epochs=3, # number of training epochs\n",
        "    per_device_train_batch_size=32, # batch size for training\n",
        "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
        "    eval_steps = 40, # Number of update steps between two evaluations.\n",
        "    save_steps=80, # after # steps model is saved\n",
        "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
        "    prediction_loss_only=True,\n",
        "    )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")"
      ],
      "metadata": {
        "id": "upQR1LvFnK1S",
        "outputId": "c169d2ae-1f14-4a38-d529-05798cd0f8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-09f0e94acc16>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m training_args = TrainingArguments(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#The output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# overwrite_output_dir=True, #overwrite the content of the output directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, evaluation_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp...\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"npu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"xpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36mdevice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \"\"\"\n\u001b[1;32m   1994\u001b[0m         \u001b[0mrequires_backends\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_devices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, objtype)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/training_args.py\u001b[0m in \u001b[0;36m_setup_devices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1903\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m                 raise ImportError(\n\u001b[0m\u001b[1;32m   1906\u001b[0m                     \u001b[0;34mf\"Using the `Trainer` with `PyTorch` requires `accelerate>={ACCELERATE_MIN_VERSION}`: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m                     \u001b[0;34m\"Please run `pip install transformers[torch]` or `pip install accelerate -U`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.21.0`: Please run `pip install transformers[torch]` or `pip install accelerate -U`",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW_oJ87-_-j9"
      },
      "source": [
        "2. Run the same training loop but modify one of the hyperparameters from this list:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip uninstall transformers"
      ],
      "metadata": {
        "id": "nOOgdP5j0528",
        "outputId": "75785028-0faf-48bc-ff3f-56dce0ed20bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.38.2\n",
            "Uninstalling transformers-4.38.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/transformers-cli\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers-4.38.2.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/transformers/*\n",
            "Proceed (Y/n)? "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/uninstall.py\", line 105, in run\n",
            "    uninstall_pathset = req.uninstall(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_install.py\", line 680, in uninstall\n",
            "    uninstalled_pathset.remove(auto_confirm, verbose)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 375, in remove\n",
            "    if auto_confirm or self._allowed_to_proceed(verbose):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/req/req_uninstall.py\", line 415, in _allowed_to_proceed\n",
            "    return ask(\"Proceed (Y/n)? \", (\"y\", \"n\", \"\")) != \"n\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 192, in ask\n",
            "    response = input(message)\n",
            "EOFError: EOF when reading a line\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'pip uninstall transformers\\n'' returned non-zero exit status 2.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-d930d49cbdc9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pip uninstall transformers\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'pip uninstall transformers\\n'' returned non-zero exit status 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAe7bcpu_-j9"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "n_embd = 64\n",
        "n_head = 4 ## so head_size = 16\n",
        "n_layer = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o--aD52C_-j9"
      },
      "source": [
        "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL3ng46d_-j9"
      },
      "source": [
        "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbyOtGAb_-j9"
      },
      "source": [
        "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDXLTusqxXHf"
      },
      "source": [
        "## References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFaJxMg9_-j9"
      },
      "source": [
        "Here are some recommendations for further reading and additional code for review.\n",
        "\n",
        "* \"The Illustrated Transformer\" by Jay Alammar\n",
        "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
        "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
        "* \"A gentle introduction to positional encoding\"\n",
        "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
        "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3fcrEcZ_-j-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}